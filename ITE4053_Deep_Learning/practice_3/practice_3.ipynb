{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "np.random.seed(97)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    def __init__(self, INPUT_DIM=(1,2,1), kernel=(1,2,1,1), stride=(1,1), OUTPUT_DIM=(1,1,1)):\n",
    "        self.INPUT_DIM = INPUT_DIM                                                                  # INPUT_DIM  == (row_i, column_i, channel_i)\n",
    "        self.OUTPUT_DIM = OUTPUT_DIM                                                                # OUTPUT_DIM == (row_o, column_o, channel_o)\n",
    "        self.KERNEL_DIM = kernel                                                                    # kernel     == (row_k, column_k, channel_i, channel_o)\n",
    "        self.stride = stride                                                                        # stride     == (row_s, column_s)    \n",
    "\n",
    "#         self.w = np.zeros(self.KERNEL_DIM, dtype=np.float64)                                        # w_dim      == (row_k, column_k, channel_i) * channel_o\n",
    "#         self.b = np.zeros(self.OUTPUT_DIM[-1], dtype=np.float64)                                    # b_dim      == 1 * channel_o\n",
    "        self.w = np.random.uniform(-1, 1, self.KERNEL_DIM)                                          # w_dim      == (row_k, column_k, channel_i) * channel_o\n",
    "        self.b = np.random.uniform(-1, 1, self.OUTPUT_DIM[-1])                                      # b_dim      == 1 * channel_o\n",
    "\n",
    "    def forward(self, X):\n",
    "        MIN_MARGIN = 2 ** -53\n",
    "                    \n",
    "        for row_idx in range(self.OUTPUT_DIM[0]):\n",
    "            row_s = row_idx * self.stride[0]\n",
    "            row_e = row_s + self.KERNEL_DIM[0]                                              \n",
    "            for column_idx in range(self.OUTPUT_DIM[1]):\n",
    "                column_s = column_idx * self.stride[1]\n",
    "                column_e = column_s + self.KERNEL_DIM[1]                                \n",
    "                for channel_o_idx in range(self.OUTPUT_DIM[2]): \n",
    "\n",
    "                    tmp_z = self.w[:,:,:,channel_o_idx] * X[:, row_s:row_e, column_s:column_e, :]   #       (row_k, column_k, channel_i, 1)\n",
    "                                                                                                    # * (-1, row_k, column_k, channel_i)\n",
    "                                                                                                    # = (-1, row_k, column_k, channel_i)\n",
    "                    tmp_z = np.sum(tmp_z, axis=(1,2,3)) + self.b[channel_o_idx]                     # (-1, 1)\n",
    "                    if len(tmp_z.shape)==1:\n",
    "                        tmp_z=tmp_z.reshape(-1,1)\n",
    "                    if row_idx == 0 and column_idx == 0 and channel_o_idx == 0:\n",
    "                        self.z = tmp_z\n",
    "                    else:\n",
    "                        self.z = np.concatenate((self.z, tmp_z), axis=1)\n",
    "                                                                                                        \n",
    "                            \n",
    "        self.z = self.z.reshape((-1,)+self.OUTPUT_DIM)                                              # (-1, row_o , column_o , channel_o)\n",
    "\n",
    "        \n",
    "        self.a = 1 / (1 + np.exp(-self.z))                                                          # (-1, row_o , column_o , channel_o)\n",
    "        self.a = np.maximum(np.minimum(1 - MIN_MARGIN, self.a), MIN_MARGIN)                         # (-1, row_o , column_o , channel_o)\n",
    "        return self.a                                                                               # (-1, row_o , column_o , channel_o)\n",
    "\n",
    "\n",
    "    def backward(self, X, dx_next, learning_rate):\n",
    "        # x_next == a_now\n",
    "        # dx_next == da_now\n",
    "        # dx_next == d_loss / dx_next == d_loss / da_now\n",
    "        # == da\n",
    "        da = dx_next                                                                                # (-1, row_o , column_o , channel_o)\n",
    "        dz = self.a * (1 - self.a) * da                                                             # (-1, row_o , column_o , channel_o)\n",
    "        dx = np.zeros(X.shape, dtype=np.float64)                                                    # (-1, row_i , column_i , channel_i)\n",
    "        # check each \"filters\" in total kernel!\n",
    "        for channel_o_idx in range(self.OUTPUT_DIM[2]):\n",
    "            for row_idx in range(self.OUTPUT_DIM[0]):\n",
    "                row_s = row_idx * self.stride[0]\n",
    "                row_e = row_s + self.KERNEL_DIM[0]                                              \n",
    "                for column_idx in range(self.OUTPUT_DIM[1]):\n",
    "                    column_s = column_idx * self.stride[1]\n",
    "                    column_e = column_s + self.KERNEL_DIM[1]                                \n",
    "                    \n",
    "                    # set dw\n",
    "                    X_selected = X[:, row_s:row_e, column_s:column_e, :]                            # (-1, row_k, column_k, channel_i)\n",
    "                    dz_selected = dz[:, row_idx, column_idx, channel_o_idx].reshape(-1,1,1,1)       # (-1,     1,        1,         1)\n",
    "                    \n",
    "                    if row_idx == 0 and column_idx == 0:\n",
    "                        dw = X_selected * dz_selected                                               #   (-1, row_k, column_k, channel_i) \n",
    "                    else:                                                                           # * (-1,     1,        1,         1)\n",
    "                        dw += X_selected * dz_selected                                              # = (-1, row_k, column_k, channel_i) \n",
    "                    \n",
    "                    # set dx\n",
    "                    w_selected = self.w[:,:,:,channel_o_idx]                                        #     (row_k, column_k, channel_i, 1)\n",
    "                    dx[:, row_s:row_e, column_s:column_e, :] += dz_selected * w_selected            # (-1, row_k, column_k, channel_i, 1)\n",
    "            \n",
    "            dw = np.mean(dw, axis=0)                                                                # (1, row_k, column_k, channel_i)\n",
    "            db = np.mean(np.sum(dz[:,:,:,channel_o_idx], axis=(1,2)), axis=0)                       # (1, 1)\n",
    "            \n",
    "            # update weights of current \"filter\" in total kernel\n",
    "            # current \"filter\" == channel_th filter of kernel\n",
    "            self.w[:,:,:,channel_o_idx] -= learning_rate * dw\n",
    "            self.b[channel_o_idx] -= learning_rate * db\n",
    "        \n",
    "        dx = dx.reshape((-1,)+self.INPUT_DIM)                                                       # (-1, row_i, column_i, channel_i)\n",
    "        return dx                                                                                   # (-1, row_i, column_i, channel_i)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Interface of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.inputs = ['tmp' for i in layers]\n",
    "    \n",
    "    def forward(self, X):\n",
    "        input_mat = X\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            self.inputs[idx]=input_mat\n",
    "            input_mat = layer.forward(input_mat)\n",
    "\n",
    "        return input_mat\n",
    "        \n",
    "    def backward(self, dx_next, learning_rate):\n",
    "        # dx_next == da_now (x->z->a)\n",
    "        for layer, input_mat in zip(reversed(self.layers), reversed(self.inputs)):\n",
    "            dx_next=layer.backward(input_mat, dx_next, learning_rate)\n",
    "            \n",
    "    def train(self, X, y, learning_rate):\n",
    "        pred_y = self.forward(X)\n",
    "        dy_of_dx = -y / pred_y + (1 - y) / (1 - pred_y)\n",
    "        self.backward(dy_of_dx, learning_rate)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.round(self.forward(X))\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        pred_y = self.forward(X)\n",
    "        return -np.mean(y * np.log(pred_y) + (1 - y) * np.log(1 - pred_y))\n",
    "    \n",
    "    def print_layers(self):\n",
    "        for layer_idx, layer in enumerate(self.layers):\n",
    "            print('Layer #{}.  input : {}\\t kernel : {}\\t output : {}'.format(layer_idx+1, layer.INPUT_DIM, layer.KERNEL_DIM, layer.OUTPUT_DIM))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples_sum(sample_num):\n",
    "    X = np.random.uniform(-10, 10, (sample_num, 2))\n",
    "    y = (np.sum(X, 1) >0).astype(float)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples_mul(sample_num):\n",
    "    X = np.random.uniform(-2, 2, (sample_num, 2))\n",
    "    y = (X[:,0]*X[:,0] > X[:,1]).astype(float)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_practice_2(train_samples, test_samples, learning_rate, epochs, print_option='default'):\n",
    "    \n",
    "    train_X, train_y = create_samples_sum(train_samples)\n",
    "    test_X, test_y = create_samples_sum(test_samples)\n",
    "    if print_option != 'nothing': print('shape of samples(before): ', train_X.shape, train_y.shape)\n",
    "\n",
    "    train_X, train_y = train_X.reshape(-1,1,1,2), train_y.reshape(-1,1,1,1)\n",
    "    test_X, test_y = test_X.reshape(-1,1,1,2), test_y.reshape(-1,1,1,1)\n",
    "    if print_option != 'nothing': print('shape of samples(after): ', train_X.shape, train_y.shape)\n",
    " \n",
    "    # make model\n",
    "    model = Network(\n",
    "        layers = [\n",
    "            Layer(INPUT_DIM=(1,1,2), kernel=(1,1,2,1), stride=(1,1), OUTPUT_DIM=(1,1,1)),\n",
    "        ] \n",
    "    )\n",
    "    if print_option != 'nothing': \n",
    "        print('train_samples : ', train_samples)\n",
    "        print('test_samples  : ', test_samples)\n",
    "        print('epochs        : ', epochs)\n",
    "        print('learning_rate : ', learning_rate)\n",
    "        model.print_layers();\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(train_X, train_y, learning_rate)\n",
    "\n",
    "        if print_option == 'progress':\n",
    "            print('\\nepoch #' + str(epoch+1))\n",
    "            print('w :' + str(model.layers[0].w.reshape((1,2))))\n",
    "            print('b : ' + str(model.layers[0].b))\n",
    "            \n",
    "    return {'w': model.layers[0].w.reshape((1,2)), \n",
    "            'b': model.layers[0].b,\n",
    "            'train_loss': model.loss(train_X, train_y),\n",
    "            'test_loss': model.loss(test_X, test_y),\n",
    "            'train_acc': 100 * np.mean(model.predict(train_X).astype(bool) == train_y.astype(bool)),\n",
    "            'test_acc': 100 * np.mean(model.predict(test_X).astype(bool) == test_y.astype(bool))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_practice_3(train_samples, test_samples, learning_rate, epochs, print_option='default'):\n",
    "    \n",
    "    train_X, train_y = create_samples_mul(train_samples)\n",
    "    test_X, test_y = create_samples_mul(test_samples)\n",
    "    if print_option != 'nothing': print('shape of samples(before): ', train_X.shape, train_y.shape)\n",
    "\n",
    "    train_X, train_y = train_X.reshape(-1,1,1,2), train_y.reshape(-1,1,1,1)\n",
    "    test_X, test_y = test_X.reshape(-1,1,1,2), test_y.reshape(-1,1,1,1)\n",
    "    if print_option != 'nothing': print('shape of samples(after): ', train_X.shape, train_y.shape)\n",
    " \n",
    "    # make model\n",
    "    model = Network(\n",
    "        layers = [\n",
    "            Layer(INPUT_DIM=(1,1,2), kernel=(1,1,2,10), stride=(1,1), OUTPUT_DIM=(1,1,10)),\n",
    "            Layer(INPUT_DIM=(1,1,10), kernel=(1,1,10,5), stride=(1,1), OUTPUT_DIM=(1,1,5)),\n",
    "            Layer(INPUT_DIM=(1,1,5), kernel=(1,1,5,1), stride=(1,1), OUTPUT_DIM=(1,1,1)),\n",
    "        ] \n",
    "    )\n",
    "    if print_option != 'nothing': \n",
    "        print('train_samples : ', train_samples)\n",
    "        print('test_samples  : ', test_samples)\n",
    "        print('epochs        : ', epochs)\n",
    "        print('learning_rate : ', learning_rate)\n",
    "        model.print_layers();\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(train_X, train_y, learning_rate)\n",
    "\n",
    "        if print_option == 'progress':\n",
    "            print('\\nepoch #' + str(epoch+1))\n",
    "            print('w :' + str(model.layers[0].w.reshape((1,2))))\n",
    "            print('b : ' + str(model.layers[0].b))\n",
    "            \n",
    "    return {\n",
    "            'train_loss': model.loss(train_X, train_y),\n",
    "            'test_loss': model.loss(test_X, test_y),\n",
    "            'train_acc': 100 * np.mean(model.predict(train_X).astype(bool) == train_y.astype(bool)),\n",
    "            'test_acc': 100 * np.mean(model.predict(test_X).astype(bool) == test_y.astype(bool))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 100 # m\n",
    "test_samples = 100 # n\n",
    "learning_rate = 1e-2\n",
    "epochs = 100 # K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of samples(before):  (100, 2) (100,)\n",
      "shape of samples(after):  (100, 1, 1, 2) (100, 1, 1, 1)\n",
      "train_samples :  100\n",
      "test_samples  :  100\n",
      "epochs        :  100\n",
      "learning_rate :  0.01\n",
      "Layer #1.  input : (1, 1, 2)\t kernel : (1, 1, 2, 1)\t output : (1, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w': array([[0.3623896 , 0.38447664]]),\n",
       " 'b': array([-0.37123757]),\n",
       " 'train_loss': 0.1923212444689857,\n",
       " 'test_loss': 0.2301040789467194,\n",
       " 'train_acc': 95.0,\n",
       " 'test_acc': 91.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_practice_2(train_samples, test_samples, learning_rate, epochs)\n",
    "#run_practice_3(train_samples, test_samples, learning_rate, epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 1000 # m\n",
    "test_samples = 100 # n\n",
    "learning_rate = 0.5\n",
    "epochs = 1000 # K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  a) Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1(train_samples, test_samples, learning_rate, epochs, print_option='default'):\n",
    "    \n",
    "    train_X, train_y = create_samples_mul(train_samples)\n",
    "    test_X, test_y = create_samples_mul(test_samples)\n",
    "    if print_option != 'nothing': print('shape of samples(before): ', train_X.shape, train_y.shape)\n",
    "\n",
    "    train_X, train_y = train_X.reshape(-1,1,1,2), train_y.reshape(-1,1,1,1)\n",
    "    test_X, test_y = test_X.reshape(-1,1,1,2), test_y.reshape(-1,1,1,1)\n",
    "    if print_option != 'nothing': print('shape of samples(after): ', train_X.shape, train_y.shape)\n",
    " \n",
    "    # make model\n",
    "    model = Network(\n",
    "        layers = [\n",
    "            Layer(INPUT_DIM=(1,1,2), kernel=(1,1,2,1), stride=(1,1), OUTPUT_DIM=(1,1,1)),\n",
    "        ] \n",
    "    )\n",
    "    if print_option != 'nothing': \n",
    "        print('train_samples : ', train_samples)\n",
    "        print('test_samples  : ', test_samples)\n",
    "        print('epochs        : ', epochs)\n",
    "        print('learning_rate : ', learning_rate)\n",
    "        model.print_layers();\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(train_X, train_y, learning_rate)\n",
    "        \n",
    "        if print_option == 'progress':\n",
    "            print('\\nepoch #' + str(epoch+1))\n",
    "            print('w :' + str(model.layers[0].w.reshape((1,2))))\n",
    "            print('b : ' + str(model.layers[0].b))\n",
    "            \n",
    "    return {'w': model.layers[0].w.reshape((1,2)), \n",
    "            'b': model.layers[0].b,\n",
    "            'train_loss': model.loss(train_X, train_y),\n",
    "            'test_loss': model.loss(test_X, test_y),\n",
    "            'train_acc': 100 * np.mean(model.predict(train_X).astype(bool) == train_y.astype(bool)),\n",
    "            'test_acc': 100 * np.mean(model.predict(test_X).astype(bool) == test_y.astype(bool))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of samples(before):  (1000, 2) (1000,)\n",
      "shape of samples(after):  (1000, 1, 1, 2) (1000, 1, 1, 1)\n",
      "train_samples :  1000\n",
      "test_samples  :  100\n",
      "epochs        :  1000\n",
      "learning_rate :  0.5\n",
      "Layer #1.  input : (1, 1, 2)\t kernel : (1, 1, 2, 1)\t output : (1, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w': array([[ 0.12136027, -2.13662267]]),\n",
       " 'b': array([2.42794785]),\n",
       " 'train_loss': 0.32088295598973277,\n",
       " 'test_loss': 0.40643315780460765,\n",
       " 'train_acc': 83.2,\n",
       " 'test_acc': 80.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_task_1(train_samples, test_samples, learning_rate, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2(train_samples, test_samples, learning_rate, epochs, print_option='default'):\n",
    "    \n",
    "    train_X, train_y = create_samples_mul(train_samples)\n",
    "    test_X, test_y = create_samples_mul(test_samples)\n",
    "    if print_option != 'nothing': print('shape of samples(before): ', train_X.shape, train_y.shape)\n",
    "\n",
    "    train_X, train_y = train_X.reshape(-1,1,1,2), train_y.reshape(-1,1,1,1)\n",
    "    test_X, test_y = test_X.reshape(-1,1,1,2), test_y.reshape(-1,1,1,1)\n",
    "    if print_option != 'nothing': print('shape of samples(after): ', train_X.shape, train_y.shape)\n",
    " \n",
    "    # make model\n",
    "    model = Network(\n",
    "        layers = [\n",
    "            Layer(INPUT_DIM=(1,1,2), kernel=(1,1,2,1), stride=(1,1), OUTPUT_DIM=(1,1,1)),\n",
    "            Layer(INPUT_DIM=(1,1,1), kernel=(1,1,1,1), stride=(1,1), OUTPUT_DIM=(1,1,1)),\n",
    "        ] \n",
    "    )\n",
    "    if print_option != 'nothing': \n",
    "        print('train_samples : ', train_samples)\n",
    "        print('test_samples  : ', test_samples)\n",
    "        print('epochs        : ', epochs)\n",
    "        print('learning_rate : ', learning_rate)\n",
    "        model.print_layers();\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(train_X, train_y, learning_rate)\n",
    "        \n",
    "        if print_option == 'progress':\n",
    "            print('\\nepoch #' + str(epoch+1))\n",
    "            print('w :' + str(model.layers[0].w.reshape((1,2))))\n",
    "            print('b : ' + str(model.layers[0].b))\n",
    "            \n",
    "    return {'w0': model.layers[0].w.reshape((1,2)), \n",
    "            'b0': model.layers[0].b,\n",
    "            'w1': model.layers[1].w.reshape((1,1)), \n",
    "            'b1': model.layers[1].b,\n",
    "            'train_loss': model.loss(train_X, train_y),\n",
    "            'test_loss': model.loss(test_X, test_y),\n",
    "            'train_acc': 100 * np.mean(model.predict(train_X).astype(bool) == train_y.astype(bool)),\n",
    "            'test_acc': 100 * np.mean(model.predict(test_X).astype(bool) == test_y.astype(bool))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of samples(before):  (1000, 2) (1000,)\n",
      "shape of samples(after):  (1000, 1, 1, 2) (1000, 1, 1, 1)\n",
      "train_samples :  1000\n",
      "test_samples  :  100\n",
      "epochs        :  1000\n",
      "learning_rate :  0.5\n",
      "Layer #1.  input : (1, 1, 2)\t kernel : (1, 1, 2, 1)\t output : (1, 1, 1)\n",
      "Layer #2.  input : (1, 1, 1)\t kernel : (1, 1, 1, 1)\t output : (1, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w0': array([[1.0546917 , 3.82076333]]),\n",
       " 'b0': array([-0.42414055]),\n",
       " 'w1': array([[-5.26771531]]),\n",
       " 'b1': array([4.79376737]),\n",
       " 'train_loss': 0.3197236111774917,\n",
       " 'test_loss': 0.31104145063535904,\n",
       " 'train_acc': 81.39999999999999,\n",
       " 'test_acc': 82.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_task_2(train_samples, test_samples, learning_rate, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3(train_samples, test_samples, learning_rate, epochs, print_option='default'):\n",
    "    \n",
    "    train_X, train_y = create_samples_mul(train_samples)\n",
    "    test_X, test_y = create_samples_mul(test_samples)\n",
    "    if print_option != 'nothing': print('shape of samples(before): ', train_X.shape, train_y.shape)\n",
    "\n",
    "    train_X, train_y = train_X.reshape(-1,1,1,2), train_y.reshape(-1,1,1,1)\n",
    "    test_X, test_y = test_X.reshape(-1,1,1,2), test_y.reshape(-1,1,1,1)\n",
    "    if print_option != 'nothing': print('shape of samples(after): ', train_X.shape, train_y.shape)\n",
    " \n",
    "    # make model\n",
    "    model = Network(\n",
    "        layers = [\n",
    "            Layer(INPUT_DIM=(1,1,2), kernel=(1,1,2,3), stride=(1,1), OUTPUT_DIM=(1,1,3)),\n",
    "            Layer(INPUT_DIM=(1,1,3), kernel=(1,1,3,1), stride=(1,1), OUTPUT_DIM=(1,1,1)),\n",
    "        ] \n",
    "    )\n",
    "    if print_option != 'nothing': \n",
    "        print('train_samples : ', train_samples)\n",
    "        print('test_samples  : ', test_samples)\n",
    "        print('epochs        : ', epochs)\n",
    "        print('learning_rate : ', learning_rate)\n",
    "        model.print_layers();\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(train_X, train_y, learning_rate)\n",
    "        \n",
    "        if print_option == 'progress':\n",
    "            print('\\nepoch #' + str(epoch+1))\n",
    "            print('w :' + str(model.layers[0].w.reshape((1,2))))\n",
    "            print('b : ' + str(model.layers[0].b))\n",
    "            \n",
    "    return {'w0': model.layers[0].w.reshape((3,2)), \n",
    "            'b0': model.layers[0].b.reshape((3,1)),\n",
    "            'w1': model.layers[1].w.reshape((1,3)), \n",
    "            'b1': model.layers[1].b,\n",
    "            'train_loss': model.loss(train_X, train_y),\n",
    "            'test_loss': model.loss(test_X, test_y),\n",
    "            'train_acc': 100 * np.mean(model.predict(train_X).astype(bool) == train_y.astype(bool)),\n",
    "            'test_acc': 100 * np.mean(model.predict(test_X).astype(bool) == test_y.astype(bool))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of samples(before):  (1000, 2) (1000,)\n",
      "shape of samples(after):  (1000, 1, 1, 2) (1000, 1, 1, 1)\n",
      "train_samples :  1000\n",
      "test_samples  :  100\n",
      "epochs        :  1000\n",
      "learning_rate :  0.5\n",
      "Layer #1.  input : (1, 1, 2)\t kernel : (1, 1, 2, 3)\t output : (1, 1, 3)\n",
      "Layer #2.  input : (1, 1, 3)\t kernel : (1, 1, 3, 1)\t output : (1, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w0': array([[-4.59781693, -1.82834322],\n",
       "        [-4.78475032,  2.84941992],\n",
       "        [ 2.14553823, -2.86890021]]),\n",
       " 'b0': array([[ 1.15998563],\n",
       "        [-0.12311688],\n",
       "        [-1.59139267]]),\n",
       " 'w1': array([[-5.93242727, -2.29232352,  7.5587517 ]]),\n",
       " 'b1': array([4.2942567]),\n",
       " 'train_loss': 0.0715170417173077,\n",
       " 'test_loss': 0.09507225857137415,\n",
       " 'train_acc': 98.9,\n",
       " 'test_acc': 98.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_task_3(train_samples, test_samples, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Find Best Parameter in Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=10.0\n",
    "trials=10\n",
    "results = []\n",
    "\n",
    "while(lr>1e-3):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    for trial in range(trials):\n",
    "        result = run_task_3(train_samples, test_samples, learning_rate, epochs, print_option='nothing')\n",
    "        train_acc+=result['train_acc']\n",
    "        test_acc+=result['test_acc']\n",
    "    \n",
    "    results.append({\n",
    "        'lr': lr,\n",
    "        'train_acc':train_acc/trials,\n",
    "        'test_acc':test_acc/trials\n",
    "    })\n",
    "    lr/=1.5\n",
    "    \n",
    "print(np.array(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_learning_rate = sorted(results, key = lambda x : x['train_acc']+x['test_acc'])[-1]['lr']\n",
    "print('best_learning_rate : ', best_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Get the Result of the Best Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_task_3(train_samples, test_samples, best_learning_rate, epochs, print_option='nothing')\n",
    "while(result['test_acc']<99.5 or result['train_acc']<99.5):\n",
    "    result = run_task_3(train_samples, test_samples, learning_rate, epochs, print_option='nothing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
