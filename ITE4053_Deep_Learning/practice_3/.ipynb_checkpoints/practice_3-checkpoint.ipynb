{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "np.random.seed(97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    def __init__(self, INPUT_DIM=(1,2,1), kernel=(1,2,1,1), stride=(1,1), OUTPUT_DIM=(1,1,1)):\n",
    "        self.INPUT_DIM = INPUT_DIM                                                                  # INPUT_DIM  == (row_i, column_i, channel_i)\n",
    "        self.OUTPUT_DIM = OUTPUT_DIM                                                                # OUTPUT_DIM == (row_o, column_o, channel_o)\n",
    "        self.KERNEL_DIM = kernel                                                                    # kernel     == (row_k, column_k, channel_i, channel_o)\n",
    "        self.stride = stride                                                                        # stride     == (row_s, column_s)    \n",
    "\n",
    "        self.w = np.zeros(self.KERNEL_DIM, dtype=np.float64)                                        # w_dim      == (row_k, column_k, channel_i) * channel_o\n",
    "        self.b = np.zeros(self.OUTPUT_DIM[-1], dtype=np.float64)                                    # b_dim      == 1 * channel_o\n",
    "\n",
    "    def forward(self, X):\n",
    "        MIN_MARGIN = 2 ** -53\n",
    "                    \n",
    "        for row_idx in range(self.OUTPUT_DIM[0]):\n",
    "            row_s = row_idx * self.stride[0]\n",
    "            row_e = row_s + self.KERNEL_DIM[0]                                              \n",
    "            for column_idx in range(self.OUTPUT_DIM[1]):\n",
    "                column_s = column_idx * self.stride[1]\n",
    "                column_e = column_s + self.KERNEL_DIM[1]                                \n",
    "                for channel_o_idx in range(self.OUTPUT_DIM[2]): \n",
    "\n",
    "                    tmp_z = self.w[:,:,:,channel_o_idx] * X[:, row_s:row_e, column_s:column_e, :]   #       (row_k, column_k, channel_i, 1)\n",
    "                                                                                                    # * (-1, row_k, column_k, channel_i)\n",
    "                                                                                                    # = (-1, row_k, column_k, channel_i)\n",
    "                    tmp_z = np.sum(tmp_z, axis=(1,2,3)) + self.b[channel_o_idx]                     # (-1, 1)\n",
    "                    \n",
    "                    if row_idx == 0 and column_idx == 0:\n",
    "                        self.z = tmp_z\n",
    "                    else:\n",
    "                        self.z = np.concatenate((self.z, tmp_z), axis=1)\n",
    "                                                                                                    # (-1, row_o * column_o * channel_o)\n",
    "        self.z = self.z.reshape((-1,)+self.OUTPUT_DIM)                                              # (-1, row_o , column_o , channel_o)\n",
    "\n",
    "        \n",
    "        self.a = 1 / (1 + np.exp(-self.z))                                                          # (-1, row_o , column_o , channel_o)\n",
    "        self.a = np.maximum(np.minimum(1 - MIN_MARGIN, self.a), MIN_MARGIN)                         # (-1, row_o , column_o , channel_o)\n",
    "        return self.a                                                                               # (-1, row_o , column_o , channel_o)\n",
    "\n",
    "\n",
    "    def backward(self, X, dx_next, learning_rate):\n",
    "        # x_next == a_now\n",
    "        # dx_next == da_now\n",
    "        # dx_next == d_loss / dx_next == d_loss / da_now\n",
    "        # == da\n",
    "        da = dx_next                                                                                # (-1, row_o , column_o , channel_o)\n",
    "        dz = self.a * (1 - self.a) * da                                                             # (-1, row_o , column_o , channel_o)\n",
    "        dx = np.zeros(X.shape, dtype=np.float64)                                                    # (-1, row_i , column_i , channel_i)\n",
    "        \n",
    "        # check each \"filters\" in total kernel!\n",
    "        for channel_o_idx in range(self.OUTPUT_DIM[2]):\n",
    "            for row_idx in range(self.OUTPUT_DIM[0]):\n",
    "                row_s = row_idx * self.stride[0]\n",
    "                row_e = row_s + self.KERNEL_DIM[0]                                              \n",
    "                for column_idx in range(self.OUTPUT_DIM[1]):\n",
    "                    column_s = column_idx * self.stride[1]\n",
    "                    column_e = column_s + self.KERNEL_DIM[1]                                \n",
    "                    \n",
    "                    # set dw\n",
    "                    X_selected = X[:, row_s:row_e, column_s:column_e, :]                            # (-1, row_k, column_k, channel_i)\n",
    "                    dz_selected = dz[:, row_idx, column_idx, channel_o_idx].reshape(-1,1,1,1)       # (-1,     1,        1,         1)\n",
    "                    \n",
    "                    if row_idx == 0 and column_idx == 0:\n",
    "                        dw = X_selected * dz_selected                                               #   (-1, row_k, column_k, channel_i) \n",
    "                    else:                                                                           # * (-1,     1,        1,         1)\n",
    "                        dw += X_selected * dz_selected                                              # = (-1, row_k, column_k, channel_i) \n",
    "                    \n",
    "                    # set dx\n",
    "                    w_selected = self.w[:,:,:,channel_o_idx]                                        #     (row_k, column_k, channel_i, 1)\n",
    "                    dx[:, row_s:row_e, column_s:column_e, :] += dz_selected * w_selected            # (-1, row_k, column_k, channel_i, 1)\n",
    "            \n",
    "            dw = np.mean(dw, axis=0)                                                                # (1, row_k, column_k, channel_i)\n",
    "            db = np.mean(np.sum(dz[:,:,:,channel_o_idx], axis=(1,2)), axis=0)                       # (1, 1)\n",
    "            \n",
    "            # update weights of current \"filter\" in total kernel\n",
    "            # current \"filter\" == channel_th filter of kernel\n",
    "            self.w[:,:,:,channel_o_idx] -= learning_rate * dw\n",
    "            self.b[channel_o_idx] -= learning_rate * db\n",
    "\n",
    "        dx = dz * self.w                                                                            # (-1,1,1,1)*(1,2,1) -> (-1,1,2,1)\n",
    "        dx = dx.reshape((-1,)+self.INPUT_DIM)                                                       # (-1, row_i, column_i, channel_i)\n",
    "        \n",
    "        return dx                                                                                   # (-1, row_i, column_i, channel_i)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Interface of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.inputs = ['tmp' for i in layers]\n",
    "    \n",
    "    def forward(self, X, option=\"NULL\"):\n",
    "        input_mat = X\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            self.inputs[idx]=input_mat\n",
    "            input_mat = layer.forward(input_mat)\n",
    "            if option=='print': print(input_mat.shape)\n",
    "        return input_mat\n",
    "        \n",
    "    def backward(self, dx_next, learning_rate):\n",
    "        # dx_next == da_now (x->z->a)\n",
    "        for layer, input_mat in zip(reversed(self.layers), reversed(self.inputs)):\n",
    "            dx_next=layer.backward(input_mat, dx_next, learning_rate)\n",
    "            \n",
    "    def train(self, X, y, learning_rate, option='NULL'):\n",
    "        pred_y = self.forward(X, option)\n",
    "        dy_of_dx = -y / pred_y + (1 - y) / (1 - pred_y)\n",
    "        self.backward(dy_of_dx, learning_rate)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.round(self.forward(X))\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        pred_y = self.forward(X)\n",
    "        return -np.mean(y * np.log(pred_y) + (1 - y) * np.log(1 - pred_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(sample_num):\n",
    "    X = np.random.uniform(-10, 10, (sample_num, 2))\n",
    "    y = (np.sum(X, 1) >0).astype(float)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples_2(sample_num):\n",
    "    X = np.random.uniform(-10, 10, (sample_num, 2,2,2))\n",
    "    y = (np.sum(X, 1) >0).astype(float)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_practice_2(train_samples, test_samples, learning_rate, epochs, option='NULL'):\n",
    "    \n",
    "    # model = Model([BinaryClassifier((1,2))])\n",
    "    train_X, train_y = create_samples(train_samples)\n",
    "    test_X, test_y = create_samples(test_samples)\n",
    "    print('shape of samples(before): ', train_X.shape, train_y.shape)\n",
    "\n",
    "    train_X, train_y = train_X.reshape(-1,1,2,1), train_y.reshape(-1,1,1,1)\n",
    "    test_X, test_y = test_X.reshape(-1,1,2,1), test_y.reshape(-1,1,1,1)\n",
    "    print('shape of samples(after) : ', train_X.shape, train_y.shape)\n",
    " \n",
    "    # make model\n",
    "    model = Network(\n",
    "        layers = [\n",
    "            Layer(INPUT_DIM=(1,2,1), kernel=(1,2,1,1), stride=(1,1), OUTPUT_DIM=(1,1,1)),\n",
    "        ] \n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train(train_X, train_y, learning_rate, option)\n",
    "        if option == 'print':\n",
    "            print('\\nepoch #' + str(epoch+1))\n",
    "            print('w :' + str(model.layers[0].w.reshape((1,2))))\n",
    "            print('b : ' + str(model.layers[0].b))\n",
    "            \n",
    "    return {'w': model.layers[0].w.reshape((1,2)), \n",
    "            'b': model.layers[0].b,\n",
    "            'train_loss': model.loss(train_X, train_y),\n",
    "            'test_loss': model.loss(test_X, test_y),\n",
    "            'train_acc': 100 * np.mean(model.predict(train_X).astype(bool) == train_y.astype(bool)),\n",
    "            'test_acc': 100 * np.mean(model.predict(test_X).astype(bool) == test_y.astype(bool))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 100 # m\n",
    "test_samples = 100 # n\n",
    "learning_rate = 1e-2\n",
    "epochs = 100 # K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of samples(before):  (100, 2) (100,)\n",
      "shape of samples(after) :  (100, 1, 2, 1) (100, 1, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w': array([[0.39703262, 0.42310451]]),\n",
       " 'b': array([0.03871357]),\n",
       " 'train_loss': 0.18211930090828615,\n",
       " 'test_loss': 0.15344904172458768,\n",
       " 'train_acc': 99.0,\n",
       " 'test_acc': 96.0}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_practice_2(train_samples, test_samples, learning_rate, epochs, option='NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
