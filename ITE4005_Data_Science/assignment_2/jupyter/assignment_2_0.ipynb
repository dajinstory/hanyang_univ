{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = {\n",
    "    # buys computer\n",
    "    'age':{\n",
    "        '<=30' : 1,\n",
    "        '31...40' : 2,\n",
    "        '>40' : 3\n",
    "    },\n",
    "    'income':{\n",
    "        'low':1,\n",
    "        'medium':2,\n",
    "        'high':3\n",
    "    },\n",
    "    'student':{\n",
    "        'no':0,\n",
    "        'yes':1\n",
    "    },\n",
    "    'credit_rating':{\n",
    "        'fair':0,\n",
    "        'excellent':1\n",
    "    },\n",
    "    'Class:buys_computer':{\n",
    "        'no':0,\n",
    "        'yes':1\n",
    "    },\n",
    "    \n",
    "    # car evaluation\n",
    "    'buying':{\n",
    "        'low':1,\n",
    "        'med':2,\n",
    "        'high':3,\n",
    "        'vhigh':4\n",
    "    },\n",
    "    'maint':{\n",
    "        'low':1,\n",
    "        'med':2,\n",
    "        'high':3,\n",
    "        'vhigh':4\n",
    "    },\n",
    "    'doors':{\n",
    "        '2':2,\n",
    "        '3':3,\n",
    "        '4':4,\n",
    "        '5more':5\n",
    "    },\n",
    "    'persons':{\n",
    "        '2':2,\n",
    "        '4':4,\n",
    "        'more':5\n",
    "    },\n",
    "    'lug_boot':{\n",
    "        'small':1,\n",
    "        'med':2,\n",
    "        'big':3\n",
    "    },\n",
    "    'safety':{\n",
    "        'low':1,\n",
    "        'med':2,\n",
    "        'high':3\n",
    "    },\n",
    "    'car_evaluation':{\n",
    "        'unacc':0,\n",
    "        'acc':1,\n",
    "        'good':2,\n",
    "        'vgood':3\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename_train, filename_test, filename_answer, vectorizer):\n",
    "    # load raw files\n",
    "    train_dataset_df = pd.read_csv(filename_train, delimiter='\\t')\n",
    "    test_dataset_df = pd.read_csv(filename_test, delimiter='\\t')\n",
    "    answer_dataset_df = pd.read_csv(filename_answer, delimiter='\\t')\n",
    "\n",
    "    key_label = train_dataset_df.keys()[-1]\n",
    "\n",
    "#     # type to dict list\n",
    "#     train_dataset = train_dataset_df.to_dict('records')\n",
    "#     test_dataset = test_dataset_df.to_dict('records')\n",
    "#     answer_dataset = answer_dataset_df.to_dict('records')\n",
    "\n",
    "#     # convert with vectorizer\n",
    "#     train_dataset = list(map(lambda x:{key:vectorizer[key][x[key]] for key in x.keys()}, train_dataset))\n",
    "#     test_dataset = list(map(lambda x:{key:vectorizer[key][x[key]] for key in x.keys()}, test_dataset))\n",
    "#     answer_dataset = list(map(lambda x:{key:vectorizer[key][x[key]] for key in x.keys()}, answer_dataset))\n",
    "\n",
    "#     # type to DataFrame\n",
    "#     train_dataset_df = pd.DataFrame(train_dataset)\n",
    "#     test_dataset_df = pd.DataFrame(test_dataset)\n",
    "#     answer_dataset_df = pd.DataFrame(answer_dataset)\n",
    "    \n",
    "    return train_dataset_df, test_dataset_df, answer_dataset_df, key_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_df, test_dataset_df, answer_dataset_df, key_label = load_dataset('dt_train.txt', 'dt_test.txt', 'dt_answer.txt', vectorizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, dataset_df, key_label, measure='entrophy', alpha=0.05):\n",
    "        self.dataset_df = dataset_df\n",
    "        self.key_label = key_label\n",
    "        self.measure = measure\n",
    "        self.get_impurity = self.get_entrophy if measure is 'entrophy' else self.get_GI\n",
    "        self.calc_leaf_impurity = self.calc_leaf_entrophy if measure is 'entrophy' else self.calc_leaf_GI\n",
    "        self.calc_info_gain = self.calc_info_gain_entrophy if measure is 'entrophy' else self.calc_info_gain_GI\n",
    "        \n",
    "        self.N = len(dataset_df[key_label])\n",
    "        self.impurity = self.calc_leaf_impurity(dataset_df[key_label])\n",
    "        \n",
    "        # attribute(=key) and functions to predict test sample\n",
    "        self.branch_condition = False\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.childs = [False, False]\n",
    "        self.terminal_nodes=1\n",
    "        self.is_parent = False\n",
    "        \n",
    "        \n",
    "\n",
    "    # num of data in current subtree\n",
    "    def get_N(self):\n",
    "        return self.N\n",
    "    \n",
    "    # get the impurity - entrophy\n",
    "    def get_entrophy(self):\n",
    "        if self.is_parent:\n",
    "            E_l = self.childs[0].get_entrophy()\n",
    "            E_r = self.childs[1].get_entrophy()\n",
    "            N_l = self.childs[0].get_N()\n",
    "            N_r = self.childs[1].get_N()\n",
    "            entrophy = (E_l*N_l + E_r*N_r) / self.N    \n",
    "            self.impurity=entrophy\n",
    "        return self.impurity\n",
    "    # get the impuritiy - Gini Index\n",
    "    def get_GI(self):\n",
    "        if self.is_parent:\n",
    "            GI_l = self.childs[0].get_GI()\n",
    "            GI_r = self.childs[1].get_GI()\n",
    "            N_l = self.childs[0].get_N()\n",
    "            N_r = self.childs[1].get_N()\n",
    "            GI = ( (GI_l - 1)*N_l + (GI_r - 1)*N_r ) / self.N + 1\n",
    "            self.impurity = GI\n",
    "        return self.impurity\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get the impurity - entrophy - leaf\n",
    "    def calc_leaf_entrophy(self, labels):\n",
    "        label_counts = labels.value_counts()\n",
    "        entrophy = 0.0\n",
    "        for key in label_counts.keys():\n",
    "            p = label_counts[key]/len(labels)\n",
    "            entrophy -= p*math.log(p,2)\n",
    "        return entrophy\n",
    "    # get the impurity - Gini Index - leaf\n",
    "    def calc_leaf_GI(self, labels):\n",
    "        label_counts = labels.value_counts()\n",
    "        GI = 1.0\n",
    "        for key in label_counts.keys():\n",
    "            p = label_counts[key]/len(labels)\n",
    "            GI -= p*p\n",
    "        return GI\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get info gain\n",
    "    def calc_info_gain_entrophy(self, labels, midpoint):\n",
    "        E_l = self.calc_leaf_entrophy(labels[:midpoint])\n",
    "        E_r = self.calc_leaf_entrophy(labels[midpoint:])\n",
    "        N_l = midpoint\n",
    "        N_r = self.N-midpoint\n",
    "        E = (E_l*N_l + E_r*N_r) / self.N\n",
    "        return E\n",
    "    # get info gain\n",
    "    def calc_info_gain_GI(self, labels, midpoint):\n",
    "        GI_l = self.calc_leaf_GI(labels[:midpoint])\n",
    "        GI_r = self.calc_leaf_GI(labels[midpoint:])\n",
    "        N_l = midpoint\n",
    "        N_r = self.N-midpoint\n",
    "        GI = ( (GI_l - 1)*N_l + (GI_r - 1)*N_r ) / self.N + 1\n",
    "        return GI\n",
    "  \n",
    "\n",
    "\n",
    "    def partitioning(self):\n",
    "        for key in self.dataset_df.keys():\n",
    "            if key is key_label:\n",
    "                continue\n",
    "            dataset_df_sorted = self.dataset_df.sort_values(by=[key], axis=0)\n",
    "            value_counts = dataset_df_sorted[key].value_counts().sort_index()\n",
    "            \n",
    "            midpoint=0\n",
    "            for value in value_counts.keys()[:-1]:\n",
    "                midpoint += value_counts[value]\n",
    "                impurity = self.calc_info_gain(dataset_df_sorted[key_label], midpoint)\n",
    "                if impurity<self.impurity :                    \n",
    "                    self.impurity = impurity\n",
    "                    dataset_sorted = dataset_df_sorted.to_dict('records')\n",
    "                    dataset_df_l = pd.DataFrame(dataset_sorted[:midpoint])\n",
    "                    dataset_df_r = pd.DataFrame(dataset_sorted[midpoint:])\n",
    "                    \n",
    "                    self.is_parent=True\n",
    "                    self.childs[0] = DecisionTree(dataset_df_l, key_label, self.measure, self.alpha)\n",
    "                    self.childs[1] = DecisionTree(dataset_df_r, key_label, self.measure, self.alpha)\n",
    "                    \n",
    "                    # set conditions\n",
    "                    self.branch_condition = {'key':key, 'value':value}\n",
    "\n",
    "        if self.is_parent:\n",
    "            self.childs[0].partitioning()\n",
    "            self.childs[1].partitioning()\n",
    "            self.terminal_nodes = self.childs[0].terminal_nodes + self.childs[1].terminal_nodes\n",
    "    \n",
    "    def pruning(self, N_total):\n",
    "        if not self.is_parent:\n",
    "            return\n",
    "        \n",
    "        # pruning child nodes first\n",
    "        self.childs[0].pruning(N_total)\n",
    "        self.childs[1].pruning(N_total)\n",
    "        # renew info \n",
    "        self.terminal_nodes = self.childs[0].terminal_nodes + self.childs[1].terminal_nodes\n",
    "        self.impurity = self.get_impurity()\n",
    "        \n",
    "        labels = self.dataset_df[self.key_label]\n",
    "        leaf_impurity = self.calc_leaf_impurity(labels)\n",
    "        if leaf_impurity*self.N/N_total + self.alpha*1 < self.impurity*self.N/N_total + self.alpha*self.terminal_nodes:\n",
    "        #if (leaf_impurity-1)*self.N/N_total + 1 + self.alpha*1 < (self.impurity-1)*self.N/N_total + 1 + self.alpha*self.terminal_nodes:\n",
    "            self.impurity = leaf_impurity\n",
    "            self.childs[0]=False\n",
    "            self.childs[1]=False\n",
    "            self.is_parent=False\n",
    "            self.terminal_nodes = 1\n",
    "            \n",
    "    def predict(self, data):\n",
    "        if self.is_parent:\n",
    "            branch_key = self.branch_condition['key']\n",
    "            branch_value = self.branch_condition['value']\n",
    "            child_num = 0 if data[branch_key]<=branch_value else 1\n",
    "            return self.childs[child_num].predict(data)\n",
    "        labels = self.dataset_df[self.key_label]\n",
    "        return labels.value_counts().idxmax()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_df, test_dataset_df, answer_dataset_df, key_label = load_dataset('dt_train.txt', \n",
    "                                                                               'dt_test.txt', \n",
    "                                                                               'dt_answer.txt', \n",
    "                                                                               vectorizer)\n",
    "test_dataset = test_dataset_df.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTree(train_dataset_df, key_label, measure='GI')\n",
    "decision_tree.partitioning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 5 / 5\n"
     ]
    }
   ],
   "source": [
    "results = [decision_tree.predict(data) for data in test_dataset] == answer_dataset_df[key_label]\n",
    "print('Accuracy : {} / {}'.format(results.value_counts()[True], len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree.pruning(14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 5 / 5\n"
     ]
    }
   ],
   "source": [
    "results = [decision_tree.predict(data) for data in test_dataset] == answer_dataset_df[key_label]\n",
    "print('Accuracy : {} / {}'.format(results.value_counts()[True], len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_df, test_dataset_df, answer_dataset_df, key_label = load_dataset('dt_train1.txt', \n",
    "                                                                               'dt_test1.txt', \n",
    "                                                                               'dt_answer1.txt', \n",
    "                                                                               vectorizer)\n",
    "test_dataset = test_dataset_df.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTree(train_dataset_df, key_label, measure='entrophy', alpha=0.01)\n",
    "decision_tree.partitioning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 341 / 346\n"
     ]
    }
   ],
   "source": [
    "results = [decision_tree.predict(data) for data in test_dataset] == answer_dataset_df[key_label]\n",
    "print('Accuracy : {} / {}'.format(results.value_counts()[True], len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree.pruning(1382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 317 / 346\n"
     ]
    }
   ],
   "source": [
    "results = [decision_tree.predict(data) for data in test_dataset] == answer_dataset_df[key_label]\n",
    "print('Accuracy : {} / {}'.format(results.value_counts()[True], len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
