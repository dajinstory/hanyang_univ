{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, Reshape, Concatenate, Dot\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename_train, filename_test):\n",
    "    dataset_train_df = pd.read_csv(filename_train, names=['user_id','movie_id','rating','time_stamp'], header=None, delimiter='\\t')\n",
    "    dataset_test_df = pd.read_csv(filename_test, names=['user_id','movie_id','rating','time_stamp'], header=None, delimiter='\\t')\n",
    "    return dataset_train_df, dataset_test_df  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(labels):\n",
    "    encodeds = [\n",
    "        [1., .0, .0, .0, .0],\n",
    "        [.0, 1., .0, .0, .0],\n",
    "        [.0, .0, 1., .0, .0],\n",
    "        [.0, .0, .0, 1., .0],\n",
    "        [.0, .0, .0, .0, 1.],\n",
    "    ]\n",
    "    labels_encoded = np.array([encodeds[int(label)-1] for label in labels])\n",
    "    return labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_smoothing(labels):\n",
    "    encodeds = [\n",
    "        [.75, .25, .0, .0, .0],\n",
    "        [.15, .7, .15, .0, .0],\n",
    "        [.0, .15, .7, .15, .0],\n",
    "        [.0, .0, .15, .7, .15],\n",
    "        [.0, .0, .0, .25, .75],\n",
    "    ]\n",
    "    labels_encoded = np.array([encodeds[int(label)-1] for label in labels])\n",
    "    return labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_df, dataset_test_df = load_dataset(filename_train='../data/train/u1.base', filename_test='../data/train/u1.test')\n",
    "\n",
    "train_x_user = dataset_train_df['user_id'].values\n",
    "train_x_item = dataset_train_df['movie_id'].values\n",
    "train_y = dataset_train_df['rating'].values\n",
    "train_y_encoded = one_hot_encoding(train_y)\n",
    "train_y_encoded_smoothing = one_hot_encoding_smoothing(train_y)\n",
    "\n",
    "test_x_user = dataset_test_df['user_id'].values\n",
    "test_x_item = dataset_test_df['movie_id'].values\n",
    "test_y = dataset_test_df['rating'].values\n",
    "test_y_encoded = one_hot_encoding(test_y)\n",
    "test_y_encoded_smoothing = one_hot_encoding_smoothing(test_y)\n",
    "\n",
    "num_of_users = dataset_train_df['user_id'].max() + 1\n",
    "num_of_items = dataset_train_df['movie_id'].max() + 1\n",
    "num_of_factors = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our own plot function\n",
    "def scatter(y, pred_y, subtitle='result.png'):\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    \n",
    "    \n",
    "    sc = ax.scatter(y, pred_y, lw=0, s=40)\n",
    "    plt.xlim(-2, 7)\n",
    "    plt.ylim(-2, 7)\n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make CFModel (Collaborative-Filtering Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) model #1 - embedded vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFModel(Model):\n",
    "    def __init__(self, num_of_users, num_of_items, num_of_factors):\n",
    "        # tensor_0 : input id\n",
    "        \n",
    "        # layer_0 : embedding id to vector\n",
    "        model_Embedding_user_id = Sequential([\n",
    "            Embedding(num_of_users, num_of_factors, input_length=1, input_shape=(1,)),\n",
    "            Reshape((num_of_factors,)),\n",
    "        ])\n",
    "        model_Embedding_item_id = Sequential([\n",
    "            Embedding(num_of_items, num_of_factors, input_length=1, input_shape=(1,)),\n",
    "            Reshape((num_of_factors,))\n",
    "        ])\n",
    "    \n",
    "        # tensor_1 : input vector\n",
    "        input_user_id = Input((1,), name='input_user_id')\n",
    "        input_item_id = Input((1,), name='input_item_id')\n",
    "        embedded_user_id = model_Embedding_user_id(input_user_id)\n",
    "        embedded_item_id = model_Embedding_item_id(input_item_id)\n",
    "\n",
    "        # tensor_2 : output label\n",
    "        output_label = Dot(axes=1)([embedded_user_id, embedded_item_id])\n",
    "        \n",
    "        super(CFModel, self).__init__(\n",
    "            inputs=[input_user_id, input_item_id], \n",
    "            outputs=output_label\n",
    "        )\n",
    "        \n",
    "    def score(self, y, pred_y):\n",
    "        return np.sqrt( np.sum(np.square(pred_y.reshape(-1, 1) - y.reshape(-1,1))) / len(y) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFModel2(Model):\n",
    "    def __init__(self, num_of_users, num_of_items, num_of_factors):\n",
    "        # tensor_0 : input id\n",
    "        \n",
    "        # layer_0 : embedding id to vector\n",
    "        model_Embedding_user_id = Sequential([\n",
    "            Embedding(num_of_users, num_of_factors, input_length=1, input_shape=(1,)),\n",
    "            Reshape((num_of_factors,)),\n",
    "        ])\n",
    "        model_Embedding_item_id = Sequential([\n",
    "            Embedding(num_of_items, num_of_factors, input_length=1, input_shape=(1,)),\n",
    "            Reshape((num_of_factors,))\n",
    "        ])\n",
    "    \n",
    "        # tensor_1 : input vector\n",
    "        input_user_id = Input((1,), name='input_user_id')\n",
    "        input_item_id = Input((1,), name='input_item_id')\n",
    "        embedded_user_id = model_Embedding_user_id(input_user_id)\n",
    "        embedded_item_id = model_Embedding_item_id(input_item_id)\n",
    "        \n",
    "        # layer_1 : extract feature of embedded vector\n",
    "        p_dropout=0.1\n",
    "        model_feuturing = Sequential([\n",
    "            Dense(200, activation='relu'),\n",
    "            Dense(100, activation='relu'),\n",
    "            Dense(20, activation='relu'),\n",
    "        ])\n",
    "   \n",
    "        # tensor_2 : \n",
    "        featured_user_id = model_feuturing(embedded_user_id)\n",
    "        featured_item_id = model_feuturing(embedded_item_id)\n",
    "        \n",
    "        # tensor_3\n",
    "        output_label = Dot(axes=1)([featured_user_id, featured_item_id])\n",
    "        \n",
    "        super(CFModel2, self).__init__(\n",
    "            inputs=[input_user_id, input_item_id], \n",
    "            outputs=output_label\n",
    "        )\n",
    "        \n",
    "    def score(self, y, pred_y):\n",
    "        return np.sqrt( np.sum(np.square(pred_y.reshape(-1, 1) - y.reshape(-1,1))) / len(y) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cf_model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_user_id (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_item_id (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_43 (Sequential)      (None, 50)           47200       input_user_id[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_44 (Sequential)      (None, 50)           84150       input_item_id[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_17 (Dot)                    (None, 1)            0           sequential_43[1][0]              \n",
      "                                                                 sequential_44[1][0]              \n",
      "==================================================================================================\n",
      "Total params: 131,350\n",
      "Trainable params: 131,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CFModel(num_of_users, num_of_items, 50)\n",
    "#model = CFModel2(num_of_users, num_of_items, 100)\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer='adamax',\n",
    "#     optimizer='adam',\n",
    "#     optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 13.6998 - val_loss: 13.8316\n",
      "Epoch 2/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 13.6806 - val_loss: 13.8098\n",
      "Epoch 3/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 13.6018 - val_loss: 13.6997\n",
      "Epoch 4/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 13.3386 - val_loss: 13.3760\n",
      "Epoch 5/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 12.7489 - val_loss: 12.7402\n",
      "Epoch 6/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 11.7783 - val_loss: 11.7928\n",
      "Epoch 7/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 10.4743 - val_loss: 10.5852\n",
      "Epoch 8/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 8.9721 - val_loss: 9.2304\n",
      "Epoch 9/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 7.4463 - val_loss: 7.8604\n",
      "Epoch 10/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 6.0774 - val_loss: 6.6142\n",
      "Epoch 11/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 4.9906 - val_loss: 5.5882\n",
      "Epoch 12/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 4.1940 - val_loss: 4.7922\n",
      "Epoch 13/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 3.6187 - val_loss: 4.1876\n",
      "Epoch 14/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 3.1880 - val_loss: 3.7215\n",
      "Epoch 15/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 2.8532 - val_loss: 3.3526\n",
      "Epoch 16/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 2.5849 - val_loss: 3.0554\n",
      "Epoch 17/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 2.3668 - val_loss: 2.8117\n",
      "Epoch 18/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 2.1870 - val_loss: 2.6087\n",
      "Epoch 19/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 2.0370 - val_loss: 2.4370\n",
      "Epoch 20/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.9104 - val_loss: 2.2914\n",
      "Epoch 21/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.8025 - val_loss: 2.1655\n",
      "Epoch 22/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.7097 - val_loss: 2.0575\n",
      "Epoch 23/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.6293 - val_loss: 1.9631\n",
      "Epoch 24/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.5596 - val_loss: 1.8802\n",
      "Epoch 25/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.4982 - val_loss: 1.8068\n",
      "Epoch 26/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.4442 - val_loss: 1.7408\n",
      "Epoch 27/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.3963 - val_loss: 1.6823\n",
      "Epoch 28/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.3538 - val_loss: 1.6298\n",
      "Epoch 29/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.3157 - val_loss: 1.5822\n",
      "Epoch 30/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.2815 - val_loss: 1.5387\n",
      "Epoch 31/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.2508 - val_loss: 1.4997\n",
      "Epoch 32/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.2230 - val_loss: 1.4638\n",
      "Epoch 33/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.1976 - val_loss: 1.4310\n",
      "Epoch 34/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.1745 - val_loss: 1.4006\n",
      "Epoch 35/1000\n",
      "80000/80000 [==============================] - 1s 10us/sample - loss: 1.1534 - val_loss: 1.3730\n",
      "Epoch 36/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.1341 - val_loss: 1.3473\n",
      "Epoch 37/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.1165 - val_loss: 1.3240\n",
      "Epoch 38/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.1001 - val_loss: 1.3024\n",
      "Epoch 39/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.0850 - val_loss: 1.2822\n",
      "Epoch 40/1000\n",
      "80000/80000 [==============================] - 1s 10us/sample - loss: 1.0712 - val_loss: 1.2634\n",
      "Epoch 41/1000\n",
      "80000/80000 [==============================] - 1s 10us/sample - loss: 1.0583 - val_loss: 1.2461\n",
      "Epoch 42/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.0462 - val_loss: 1.2300\n",
      "Epoch 43/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.0349 - val_loss: 1.2150\n",
      "Epoch 44/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.0245 - val_loss: 1.2008\n",
      "Epoch 45/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.0146 - val_loss: 1.1873\n",
      "Epoch 46/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 1.0054 - val_loss: 1.1749\n",
      "Epoch 47/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9966 - val_loss: 1.1631\n",
      "Epoch 48/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9886 - val_loss: 1.1521\n",
      "Epoch 49/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9808 - val_loss: 1.1421\n",
      "Epoch 50/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9735 - val_loss: 1.1324\n",
      "Epoch 51/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9667 - val_loss: 1.1232\n",
      "Epoch 52/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9602 - val_loss: 1.1147\n",
      "Epoch 53/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9539 - val_loss: 1.1062\n",
      "Epoch 54/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9479 - val_loss: 1.0985\n",
      "Epoch 55/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9422 - val_loss: 1.0912\n",
      "Epoch 56/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9367 - val_loss: 1.0842\n",
      "Epoch 57/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9315 - val_loss: 1.0778\n",
      "Epoch 58/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9264 - val_loss: 1.0716\n",
      "Epoch 59/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9216 - val_loss: 1.0656\n",
      "Epoch 60/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9169 - val_loss: 1.0598\n",
      "Epoch 61/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9124 - val_loss: 1.0544\n",
      "Epoch 62/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9081 - val_loss: 1.0493\n",
      "Epoch 63/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.9039 - val_loss: 1.0440\n",
      "Epoch 64/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8996 - val_loss: 1.0393\n",
      "Epoch 65/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8956 - val_loss: 1.0347\n",
      "Epoch 66/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8916 - val_loss: 1.0300\n",
      "Epoch 67/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8879 - val_loss: 1.0259\n",
      "Epoch 68/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8840 - val_loss: 1.0218\n",
      "Epoch 69/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8803 - val_loss: 1.0181\n",
      "Epoch 70/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8767 - val_loss: 1.0143\n",
      "Epoch 71/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8731 - val_loss: 1.0104\n",
      "Epoch 72/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8695 - val_loss: 1.0068\n",
      "Epoch 73/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8661 - val_loss: 1.0033\n",
      "Epoch 74/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8627 - val_loss: 0.9997\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8592 - val_loss: 0.9964\n",
      "Epoch 76/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8559 - val_loss: 0.9934\n",
      "Epoch 77/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8526 - val_loss: 0.9903\n",
      "Epoch 78/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8492 - val_loss: 0.9873\n",
      "Epoch 79/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8459 - val_loss: 0.9843\n",
      "Epoch 80/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8426 - val_loss: 0.9817\n",
      "Epoch 81/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8393 - val_loss: 0.9787\n",
      "Epoch 82/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8361 - val_loss: 0.9761\n",
      "Epoch 83/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8328 - val_loss: 0.9735\n",
      "Epoch 84/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8296 - val_loss: 0.9704\n",
      "Epoch 85/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8263 - val_loss: 0.9683\n",
      "Epoch 86/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8230 - val_loss: 0.9659\n",
      "Epoch 87/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8198 - val_loss: 0.9636\n",
      "Epoch 88/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8166 - val_loss: 0.9611\n",
      "Epoch 89/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8134 - val_loss: 0.9588\n",
      "Epoch 90/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8102 - val_loss: 0.9564\n",
      "Epoch 91/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8069 - val_loss: 0.9542\n",
      "Epoch 92/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8037 - val_loss: 0.9520\n",
      "Epoch 93/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.8005 - val_loss: 0.9496\n",
      "Epoch 94/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7973 - val_loss: 0.9477\n",
      "Epoch 95/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7940 - val_loss: 0.9455\n",
      "Epoch 96/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7907 - val_loss: 0.9438\n",
      "Epoch 97/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7874 - val_loss: 0.9415\n",
      "Epoch 98/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7841 - val_loss: 0.9396\n",
      "Epoch 99/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7807 - val_loss: 0.9378\n",
      "Epoch 100/1000\n",
      "80000/80000 [==============================] - 1s 10us/sample - loss: 0.7775 - val_loss: 0.9358\n",
      "Epoch 101/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7742 - val_loss: 0.9339\n",
      "Epoch 102/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7709 - val_loss: 0.9320\n",
      "Epoch 103/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7676 - val_loss: 0.9304\n",
      "Epoch 104/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7643 - val_loss: 0.9290\n",
      "Epoch 105/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7610 - val_loss: 0.9270\n",
      "Epoch 106/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7577 - val_loss: 0.9252\n",
      "Epoch 107/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7544 - val_loss: 0.9238\n",
      "Epoch 108/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7510 - val_loss: 0.9221\n",
      "Epoch 109/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7477 - val_loss: 0.9204\n",
      "Epoch 110/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7443 - val_loss: 0.9189\n",
      "Epoch 111/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7409 - val_loss: 0.9175\n",
      "Epoch 112/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7375 - val_loss: 0.9160\n",
      "Epoch 113/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7343 - val_loss: 0.9144\n",
      "Epoch 114/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7308 - val_loss: 0.9128\n",
      "Epoch 115/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7274 - val_loss: 0.9116\n",
      "Epoch 116/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7240 - val_loss: 0.9105\n",
      "Epoch 117/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7206 - val_loss: 0.9092\n",
      "Epoch 118/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7171 - val_loss: 0.9077\n",
      "Epoch 119/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7137 - val_loss: 0.9064\n",
      "Epoch 120/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7102 - val_loss: 0.9051\n",
      "Epoch 121/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7068 - val_loss: 0.9039\n",
      "Epoch 122/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.7033 - val_loss: 0.9029\n",
      "Epoch 123/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6997 - val_loss: 0.9015\n",
      "Epoch 124/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6962 - val_loss: 0.9005\n",
      "Epoch 125/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6928 - val_loss: 0.8995\n",
      "Epoch 126/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6893 - val_loss: 0.8984\n",
      "Epoch 127/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6858 - val_loss: 0.8975\n",
      "Epoch 128/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6823 - val_loss: 0.8967\n",
      "Epoch 129/1000\n",
      "80000/80000 [==============================] - 1s 10us/sample - loss: 0.6788 - val_loss: 0.8955\n",
      "Epoch 130/1000\n",
      "80000/80000 [==============================] - 1s 10us/sample - loss: 0.6752 - val_loss: 0.8945\n",
      "Epoch 131/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6716 - val_loss: 0.8937\n",
      "Epoch 132/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6682 - val_loss: 0.8925\n",
      "Epoch 133/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6646 - val_loss: 0.8917\n",
      "Epoch 134/1000\n",
      "80000/80000 [==============================] - ETA: 0s - loss: 0.660 - 1s 9us/sample - loss: 0.6610 - val_loss: 0.8911\n",
      "Epoch 135/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6574 - val_loss: 0.8902\n",
      "Epoch 136/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6538 - val_loss: 0.8896\n",
      "Epoch 137/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6501 - val_loss: 0.8888\n",
      "Epoch 138/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6466 - val_loss: 0.8880\n",
      "Epoch 139/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6430 - val_loss: 0.8876\n",
      "Epoch 140/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6393 - val_loss: 0.8865\n",
      "Epoch 141/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6357 - val_loss: 0.8860\n",
      "Epoch 142/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6321 - val_loss: 0.8853\n",
      "Epoch 143/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6285 - val_loss: 0.8848\n",
      "Epoch 144/1000\n",
      "80000/80000 [==============================] - 1s 10us/sample - loss: 0.6247 - val_loss: 0.8844\n",
      "Epoch 145/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6212 - val_loss: 0.8838\n",
      "Epoch 146/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6175 - val_loss: 0.8832\n",
      "Epoch 147/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6139 - val_loss: 0.8829\n",
      "Epoch 148/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6104 - val_loss: 0.8822\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6066 - val_loss: 0.8817\n",
      "Epoch 150/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.6031 - val_loss: 0.8815\n",
      "Epoch 151/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5994 - val_loss: 0.8809\n",
      "Epoch 152/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5958 - val_loss: 0.8806\n",
      "Epoch 153/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5922 - val_loss: 0.8803\n",
      "Epoch 154/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5885 - val_loss: 0.8799\n",
      "Epoch 155/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5849 - val_loss: 0.8798\n",
      "Epoch 156/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5812 - val_loss: 0.8794\n",
      "Epoch 157/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5775 - val_loss: 0.8792\n",
      "Epoch 158/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5738 - val_loss: 0.8791\n",
      "Epoch 159/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5702 - val_loss: 0.8789\n",
      "Epoch 160/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5665 - val_loss: 0.8787\n",
      "Epoch 161/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5628 - val_loss: 0.8785\n",
      "Epoch 162/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5592 - val_loss: 0.8784\n",
      "Epoch 163/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5555 - val_loss: 0.8784\n",
      "Epoch 164/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5519 - val_loss: 0.8781\n",
      "Epoch 165/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5483 - val_loss: 0.8780\n",
      "Epoch 166/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5447 - val_loss: 0.8782\n",
      "Epoch 167/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5410 - val_loss: 0.8780\n",
      "Epoch 168/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5373 - val_loss: 0.8782\n",
      "Epoch 169/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5337 - val_loss: 0.8784\n",
      "Epoch 170/1000\n",
      "80000/80000 [==============================] - 1s 9us/sample - loss: 0.5301 - val_loss: 0.8784\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "]\n",
    "result = model.fit(\n",
    "    [train_x_user, train_x_item], train_y,\n",
    "    batch_size = 512,\n",
    "    epochs = 1000,\n",
    "    shuffle = True,\n",
    "    verbose = True,\n",
    "    validation_data = ([test_x_user, test_x_item], test_y),\n",
    "    callbacks = callbacks,\n",
    ")\n",
    "\n",
    "model.save_weights('weights_CF.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.9372139014084944\n"
     ]
    }
   ],
   "source": [
    "pred_y = model.predict([test_x_user, test_x_item]).reshape(-1,1)\n",
    "\n",
    "print('RMSE : ', model.score(test_y, pred_y))\n",
    "#scatter(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
