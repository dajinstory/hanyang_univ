{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, Reshape, Concatenate, Dot, Multiply\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_id = 1):\n",
    "    filename_train = '../data/train/u'+str(dataset_id)+'.base'\n",
    "    filename_test = '../data/train/u'+str(dataset_id)+'.test'\n",
    "    dataset_train_df = pd.read_csv(filename_train, names=['user_id','movie_id','rating','time_stamp'], header=None, delimiter='\\t')\n",
    "    dataset_test_df = pd.read_csv(filename_test, names=['user_id','movie_id','rating','time_stamp'], header=None, delimiter='\\t')\n",
    "    # dataset = dataset_df.to_dict('records')\n",
    "    return dataset_train_df, dataset_test_df  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(labels):\n",
    "    encodeds = [\n",
    "        [1., .0, .0, .0, .0],\n",
    "        [.0, 1., .0, .0, .0],\n",
    "        [.0, .0, 1., .0, .0],\n",
    "        [.0, .0, .0, 1., .0],\n",
    "        [.0, .0, .0, .0, 1.],\n",
    "    ]\n",
    "    labels_encoded = np.array([encodeds[int(label)-1] for label in labels])\n",
    "    return labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_smoothing(labels):\n",
    "    encodeds = [\n",
    "        [.75, .25, .0, .0, .0],\n",
    "        [.15, .7, .15, .0, .0],\n",
    "        [.0, .15, .7, .15, .0],\n",
    "        [.0, .0, .15, .7, .15],\n",
    "        [.0, .0, .0, .25, .75],\n",
    "    ]\n",
    "    labels_encoded = np.array([encodeds[int(label)-1] for label in labels])\n",
    "    return labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_df, dataset_test_df = load_dataset(dataset_id=1)\n",
    "\n",
    "train_x_user = dataset_train_df['user_id'].values\n",
    "train_x_item = dataset_train_df['movie_id'].values\n",
    "train_y = dataset_train_df['rating'].values\n",
    "train_y_encoded = one_hot_encoding(train_y)\n",
    "train_y_encoded_smoothing = one_hot_encoding_smoothing(train_y)\n",
    "\n",
    "test_x_user = dataset_test_df['user_id'].values\n",
    "test_x_item = dataset_test_df['movie_id'].values\n",
    "test_y = dataset_test_df['rating'].values\n",
    "test_y_encoded = one_hot_encoding(test_y)\n",
    "test_y_encoded_smoothing = one_hot_encoding_smoothing(test_y)\n",
    "\n",
    "num_of_users = dataset_train_df['user_id'].max() + 1\n",
    "num_of_items = dataset_train_df['movie_id'].max() + 1\n",
    "num_of_factors = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our own plot function\n",
    "def scatter(y, pred_y, subtitle='result.png'):\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    \n",
    "    \n",
    "    sc = ax.scatter(y, pred_y, lw=0, s=40)\n",
    "    plt.xlim(-2, 7)\n",
    "    plt.ylim(-2, 7)\n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) model #3 - DNN with one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNModel_onehot(Model):\n",
    "    def __init__(self, num_of_users, num_of_items, num_of_factors):\n",
    "        \n",
    "        # tensor_0 : input\n",
    "        input_user_id = Input((1,), name='input_user_id')\n",
    "        input_item_id = Input((1,), name='input_item_id')\n",
    "        \n",
    "        # model_0 : embedding inpput\n",
    "        model_Embedding_user_id = Sequential([\n",
    "            Embedding(num_of_users, num_of_factors, input_length=1, input_shape=(1,)),\n",
    "            Reshape((num_of_factors,)),\n",
    "        ])\n",
    "        model_Embedding_item_id = Sequential([\n",
    "            Embedding(num_of_items, num_of_factors, input_length=1, input_shape=(1,)),\n",
    "            Reshape((num_of_factors,)),\n",
    "        ])\n",
    "        \n",
    "        # tensor_1 : embedded input\n",
    "        embedded_user_id = model_Embedding_user_id(input_user_id)\n",
    "        embedded_item_id = model_Embedding_item_id(input_item_id)\n",
    "        \n",
    "        # tensor_2 : embedded vector\n",
    "        embedded_mul = Multiply()([embedded_user_id, embedded_item_id])\n",
    "        embedded_vector = Concatenate(axis=-1)([embedded_user_id, embedded_item_id, embedded_mul])\n",
    "        \n",
    "        # model_2 : DNN\n",
    "        p_dropout=0.1\n",
    "        model_DNN = Sequential([\n",
    "            Dropout(p_dropout),\n",
    "            Dense(num_of_factors * 3, activation='relu'),\n",
    "            Dropout(p_dropout),\n",
    "            Dense(30, activation='relu'),\n",
    "            Dropout(p_dropout),\n",
    "            Dense(5, activation='softmax'),\n",
    "        ])    \n",
    "        \n",
    "        # tensor_3 : output_label\n",
    "        output_label = model_DNN(embedded_vector)\n",
    "        \n",
    "        super(DNNModel_onehot, self).__init__(\n",
    "            inputs=[input_user_id, input_item_id], \n",
    "            outputs=output_label\n",
    "        )\n",
    "\n",
    "    def score(self, y, pred_y):\n",
    "        return np.sqrt( np.sum(np.square(pred_y.reshape(-1, 1) - y.reshape(-1,1))) / len(y) )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - train model and get results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3_a) one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNModel_onehot(num_of_users, num_of_items, num_of_factors)\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/1000\n",
      "80000/80000 [==============================] - 2s 27us/sample - loss: 0.1423 - val_loss: 0.1349\n",
      "Epoch 2/1000\n",
      "80000/80000 [==============================] - 1s 12us/sample - loss: 0.1323 - val_loss: 0.1331\n",
      "Epoch 3/1000\n",
      "80000/80000 [==============================] - 1s 12us/sample - loss: 0.1297 - val_loss: 0.1332\n",
      "Epoch 4/1000\n",
      "80000/80000 [==============================] - 1s 11us/sample - loss: 0.1278 - val_loss: 0.1332\n",
      "Epoch 5/1000\n",
      "80000/80000 [==============================] - 1s 12us/sample - loss: 0.1261 - val_loss: 0.1337\n",
      "Epoch 6/1000\n",
      "80000/80000 [==============================] - 1s 11us/sample - loss: 0.1245 - val_loss: 0.1344\n",
      "Epoch 7/1000\n",
      "80000/80000 [==============================] - 1s 11us/sample - loss: 0.1228 - val_loss: 0.1351\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "]\n",
    "result = model.fit(\n",
    "    [train_x_user, train_x_item], train_y_encoded,\n",
    "    batch_size = 512,\n",
    "    epochs = 1000,\n",
    "    shuffle = True,\n",
    "    verbose = True,\n",
    "    validation_data = ([test_x_user, test_x_item], test_y_encoded),\n",
    "    callbacks = callbacks,\n",
    ")\n",
    "\n",
    "model.save_weights('weights_DNN_onehot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1.3567424221273543\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y_encoded = model.predict([test_x_user, test_x_item]).reshape(-1,1)\n",
    "pred_y = pred_y_encoded.reshape(-1,5,).argmax(axis=1)\n",
    "\n",
    "print('RMSE : ', model.score(test_y, pred_y))\n",
    "scatter(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3_b) one-hot encoding with smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNModel_onehot(num_of_users, num_of_items, num_of_factors)\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/1000\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.0583 - val_loss: 0.0540\n",
      "Epoch 2/1000\n",
      "80000/80000 [==============================] - 1s 13us/sample - loss: 0.0523 - val_loss: 0.0527\n",
      "Epoch 3/1000\n",
      "80000/80000 [==============================] - 1s 14us/sample - loss: 0.0509 - val_loss: 0.0524\n",
      "Epoch 4/1000\n",
      "29184/80000 [=========>....................] - ETA: 0s - loss: 0.0496"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "]\n",
    "result = model.fit(\n",
    "    [train_x_user, train_x_item], train_y_encoded_smoothing,\n",
    "    batch_size = 512,\n",
    "    epochs = 1000,\n",
    "    shuffle = True,\n",
    "    verbose = True,\n",
    "    validation_data = ([test_x_user, test_x_item], test_y_encoded_smoothing),\n",
    "    callbacks = callbacks,\n",
    ")\n",
    "\n",
    "model.save_weights('weights_DNN_onehot_smoothing.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_encoded = model.predict([test_x_user, test_x_item]).reshape(-1,1)\n",
    "pred_y = pred_y_encoded.reshape(-1,5,).argmax(axis=1)\n",
    "\n",
    "print('RMSE : ', model.score(test_y, pred_y))\n",
    "scatter(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3_c) one-hot encoding - ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNModel_onehot(num_of_users, num_of_items, num_of_factors)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "]\n",
    "result = model.fit(\n",
    "    [train_x_user, train_x_item], train_y_encoded,\n",
    "    batch_size = 512,\n",
    "    epochs = 1000,\n",
    "    shuffle = True,\n",
    "    verbose = True,\n",
    "    validation_data = ([test_x_user, test_x_item], test_y_encoded),\n",
    "    callbacks = callbacks,\n",
    ")\n",
    "\n",
    "model.save_weights('weights_DNN_onehot_ce.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_encoded = model.predict([test_x_user, test_x_item]).reshape(-1,1)\n",
    "pred_y = pred_y_encoded.reshape(-1,5,).argmax(axis=1)\n",
    "\n",
    "print('RMSE : ', model.score(test_y, pred_y))\n",
    "scatter(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3_d) one-hot encoding with smoothing - ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNModel_onehot(num_of_users, num_of_items, num_of_factors)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "]\n",
    "result = model.fit(\n",
    "    [train_x_user, train_x_item], train_y_encoded_smoothing,\n",
    "    batch_size = 512,\n",
    "    epochs = 1000,\n",
    "    shuffle = True,\n",
    "    verbose = True,\n",
    "    validation_data = ([test_x_user, test_x_item], test_y_encoded_smoothing),\n",
    "    callbacks = callbacks,\n",
    ")\n",
    "\n",
    "model.save_weights('weights_DNN_onehot_smoothing_ce.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_encoded = model.predict([test_x_user, test_x_item]).reshape(-1,1)\n",
    "pred_y = pred_y_encoded.reshape(-1,5,).argmax(axis=1)\n",
    "\n",
    "print('RMSE : ', model.score(test_y, pred_y))\n",
    "scatter(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
