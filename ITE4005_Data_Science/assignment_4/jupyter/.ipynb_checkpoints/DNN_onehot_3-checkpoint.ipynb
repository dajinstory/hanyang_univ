{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, Reshape, Concatenate, Dot, Multiply\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_id = 1):\n",
    "    filename_train = '../data/train/u'+str(dataset_id)+'.base'\n",
    "    filename_test = '../data/train/u'+str(dataset_id)+'.test'\n",
    "    dataset_train_df = pd.read_csv(filename_train, names=['user_id','movie_id','rating','time_stamp'], header=None, delimiter='\\t')\n",
    "    dataset_test_df = pd.read_csv(filename_train, names=['user_id','movie_id','rating','time_stamp'], header=None, delimiter='\\t')\n",
    "    # dataset = dataset_df.to_dict('records')\n",
    "    return dataset_train_df, dataset_test_df  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(labels):\n",
    "    encodeds = [\n",
    "        [1., .0, .0, .0, .0],\n",
    "        [.0, 1., .0, .0, .0],\n",
    "        [.0, .0, 1., .0, .0],\n",
    "        [.0, .0, .0, 1., .0],\n",
    "        [.0, .0, .0, .0, 1.],\n",
    "    ]\n",
    "    labels_encoded = np.array([encodeds[int(label)-1] for label in labels])\n",
    "    return labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_smoothing(labels):\n",
    "    encodeds = [\n",
    "        [.75, .25, .0, .0, .0],\n",
    "        [.15, .7, .15, .0, .0],\n",
    "        [.0, .15, .7, .15, .0],\n",
    "        [.0, .0, .15, .7, .15],\n",
    "        [.0, .0, .0, .25, .75],\n",
    "    ]\n",
    "    labels_encoded = np.array([encodeds[int(label)-1] for label in labels])\n",
    "    return labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_df, dataset_test_df = load_dataset(dataset_id=1)\n",
    "\n",
    "train_x_user = dataset_train_df['user_id'].values\n",
    "train_x_item = dataset_train_df['movie_id'].values\n",
    "train_y = dataset_train_df['rating'].values\n",
    "train_y_encoded = one_hot_encoding(train_y)\n",
    "train_y_encoded_smoothing = one_hot_encoding_smoothing(train_y)\n",
    "\n",
    "test_x_user = dataset_test_df['user_id'].values\n",
    "test_x_item = dataset_test_df['movie_id'].values\n",
    "test_y = dataset_test_df['rating'].values\n",
    "test_y_encoded = one_hot_encoding(test_y)\n",
    "test_y_encoded_smoothing = one_hot_encoding_smoothing(test_y)\n",
    "\n",
    "num_of_users = dataset_train_df['user_id'].max() + 1\n",
    "num_of_items = dataset_train_df['movie_id'].max() + 1\n",
    "num_of_factors = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our own plot function\n",
    "def scatter(y, pred_y, subtitle='result.png'):\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    \n",
    "    \n",
    "    sc = ax.scatter(y, pred_y, lw=0, s=40)\n",
    "    plt.xlim(-2, 7)\n",
    "    plt.ylim(-2, 7)\n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) model #3 - DNN with one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNModel_onehot(Model):\n",
    "    def __init__(self, num_of_users, num_of_items, num_of_factors):\n",
    "        \n",
    "        # tensor_0 : input\n",
    "        input_user_id = Input((1,), name='input_user_id')\n",
    "        input_item_id = Input((1,), name='input_item_id')\n",
    "        \n",
    "        # model_0 : embedding inpput\n",
    "        model_Embedding_user_id = Sequential([\n",
    "            Embedding(num_of_users, num_of_factors, input_length=1, input_shape=(1,)),\n",
    "            Reshape((num_of_factors,)),\n",
    "        ])\n",
    "        model_Embedding_item_id = Sequential([\n",
    "            Embedding(num_of_items, num_of_factors, input_length=1, input_shape=(1,)),\n",
    "            Reshape((num_of_factors,)),\n",
    "        ])\n",
    "        \n",
    "        # tensor_1 : embedded input\n",
    "        embedded_user_id = model_Embedding_user_id(input_user_id)\n",
    "        embedded_item_id = model_Embedding_item_id(input_item_id)\n",
    "        \n",
    "        # tensor_2 : embedded vector\n",
    "        embedded_mul = Multiply()([embedded_user_id, embedded_item_id])\n",
    "        embedded_vector = Concatenate(axis=-1)([embedded_user_id, embedded_item_id, embedded_mul])\n",
    "        \n",
    "        # model_2 : DNN\n",
    "        p_dropout=0.1\n",
    "        model_DNN = Sequential([\n",
    "            Dropout(p_dropout),\n",
    "            Dense(num_of_factors * 3, activation='relu'),\n",
    "            Dropout(p_dropout),\n",
    "            Dense(30, activation='relu'),\n",
    "            Dropout(p_dropout),\n",
    "            Dense(5, activation='linear'),\n",
    "        ])    \n",
    "        \n",
    "        # tensor_3 : output_label\n",
    "        output_label = model_DNN(embedded_vector)\n",
    "        \n",
    "        super(DNNModel_onehot, self).__init__(\n",
    "            inputs=[input_user_id, input_item_id], \n",
    "            outputs=output_label\n",
    "        )\n",
    "\n",
    "    def score(self, y, pred_y):\n",
    "        return np.sqrt( np.sum(np.square(pred_y.reshape(-1, 1) - y.reshape(-1,1))) / len(y) )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - train model and get results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3_a) one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNModel_onehot(num_of_users, num_of_items, num_of_factors)\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 80000 samples\n",
      "Epoch 1/1000\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.1442 - val_loss: 0.1311\n",
      "Epoch 2/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.1334 - val_loss: 0.1266\n",
      "Epoch 3/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.1303 - val_loss: 0.1241\n",
      "Epoch 4/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.1277 - val_loss: 0.1211\n",
      "Epoch 5/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.1249 - val_loss: 0.1166\n",
      "Epoch 6/1000\n",
      "80000/80000 [==============================] - 1s 18us/sample - loss: 0.1215 - val_loss: 0.1108\n",
      "Epoch 7/1000\n",
      "80000/80000 [==============================] - 2s 19us/sample - loss: 0.1165 - val_loss: 0.1021\n",
      "Epoch 8/1000\n",
      "80000/80000 [==============================] - 1s 17us/sample - loss: 0.1097 - val_loss: 0.0925\n",
      "Epoch 9/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.1017 - val_loss: 0.0821\n",
      "Epoch 10/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0933 - val_loss: 0.0725\n",
      "Epoch 11/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0856 - val_loss: 0.0642\n",
      "Epoch 12/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0789 - val_loss: 0.0573\n",
      "Epoch 13/1000\n",
      "80000/80000 [==============================] - 2s 24us/sample - loss: 0.0731 - val_loss: 0.0520\n",
      "Epoch 14/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0680 - val_loss: 0.0472\n",
      "Epoch 15/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0637 - val_loss: 0.0433\n",
      "Epoch 16/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0597 - val_loss: 0.0397\n",
      "Epoch 17/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0567 - val_loss: 0.0371\n",
      "Epoch 18/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0538 - val_loss: 0.0345\n",
      "Epoch 19/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0515 - val_loss: 0.0322\n",
      "Epoch 20/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0489 - val_loss: 0.0301\n",
      "Epoch 21/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0469 - val_loss: 0.0286\n",
      "Epoch 22/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0449 - val_loss: 0.0270\n",
      "Epoch 23/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0434 - val_loss: 0.0252\n",
      "Epoch 24/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0419 - val_loss: 0.0241\n",
      "Epoch 25/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0404 - val_loss: 0.0227\n",
      "Epoch 26/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0388 - val_loss: 0.0217\n",
      "Epoch 27/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0375 - val_loss: 0.0205\n",
      "Epoch 28/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0362 - val_loss: 0.0196\n",
      "Epoch 29/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0353 - val_loss: 0.0187\n",
      "Epoch 30/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0344 - val_loss: 0.0178\n",
      "Epoch 31/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0330 - val_loss: 0.0171\n",
      "Epoch 32/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0323 - val_loss: 0.0162\n",
      "Epoch 33/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0314 - val_loss: 0.0157\n",
      "Epoch 34/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0303 - val_loss: 0.0149\n",
      "Epoch 35/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0297 - val_loss: 0.0142\n",
      "Epoch 36/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0289 - val_loss: 0.0137\n",
      "Epoch 37/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0280 - val_loss: 0.0132\n",
      "Epoch 38/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0272 - val_loss: 0.0127\n",
      "Epoch 39/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0265 - val_loss: 0.0121\n",
      "Epoch 40/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0262 - val_loss: 0.0117\n",
      "Epoch 41/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0255 - val_loss: 0.0113\n",
      "Epoch 42/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0250 - val_loss: 0.0109\n",
      "Epoch 43/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0246 - val_loss: 0.0106\n",
      "Epoch 44/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0241 - val_loss: 0.0103\n",
      "Epoch 45/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0237 - val_loss: 0.0100\n",
      "Epoch 46/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0232 - val_loss: 0.0096\n",
      "Epoch 47/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0228 - val_loss: 0.0093\n",
      "Epoch 48/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0226 - val_loss: 0.0091\n",
      "Epoch 49/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0223 - val_loss: 0.0087\n",
      "Epoch 50/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0215 - val_loss: 0.0085\n",
      "Epoch 51/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0216 - val_loss: 0.0083\n",
      "Epoch 52/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0213 - val_loss: 0.0080\n",
      "Epoch 53/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0208 - val_loss: 0.0079\n",
      "Epoch 54/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0205 - val_loss: 0.0076\n",
      "Epoch 55/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0201 - val_loss: 0.0075\n",
      "Epoch 56/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0200 - val_loss: 0.0073\n",
      "Epoch 57/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0198 - val_loss: 0.0072\n",
      "Epoch 58/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0196 - val_loss: 0.0071\n",
      "Epoch 59/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0194 - val_loss: 0.0068\n",
      "Epoch 60/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0191 - val_loss: 0.0066\n",
      "Epoch 61/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0188 - val_loss: 0.0065\n",
      "Epoch 62/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0185 - val_loss: 0.0065\n",
      "Epoch 63/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0183 - val_loss: 0.0062\n",
      "Epoch 64/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0182 - val_loss: 0.0062\n",
      "Epoch 65/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0179 - val_loss: 0.0060\n",
      "Epoch 66/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0181 - val_loss: 0.0060\n",
      "Epoch 67/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0178 - val_loss: 0.0058\n",
      "Epoch 68/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0174 - val_loss: 0.0057\n",
      "Epoch 69/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0172 - val_loss: 0.0056\n",
      "Epoch 70/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0172 - val_loss: 0.0055\n",
      "Epoch 71/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0170 - val_loss: 0.0055\n",
      "Epoch 72/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0171 - val_loss: 0.0054\n",
      "Epoch 73/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0168 - val_loss: 0.0052\n",
      "Epoch 74/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0169 - val_loss: 0.0052\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0166 - val_loss: 0.0051\n",
      "Epoch 76/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0167 - val_loss: 0.0051\n",
      "Epoch 77/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0163 - val_loss: 0.0050\n",
      "Epoch 78/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0166 - val_loss: 0.0050\n",
      "Epoch 79/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0162 - val_loss: 0.0049\n",
      "Epoch 80/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0161 - val_loss: 0.0048\n",
      "Epoch 81/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0160 - val_loss: 0.0047\n",
      "Epoch 82/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0158 - val_loss: 0.0047\n",
      "Epoch 83/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0156 - val_loss: 0.0046\n",
      "Epoch 84/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0155 - val_loss: 0.0046\n",
      "Epoch 85/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0155 - val_loss: 0.0045\n",
      "Epoch 86/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0154 - val_loss: 0.0044\n",
      "Epoch 87/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0155 - val_loss: 0.0044\n",
      "Epoch 88/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0154 - val_loss: 0.0044\n",
      "Epoch 89/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0152 - val_loss: 0.0043\n",
      "Epoch 90/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0149 - val_loss: 0.0042\n",
      "Epoch 91/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0151 - val_loss: 0.0042\n",
      "Epoch 92/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0149 - val_loss: 0.0041\n",
      "Epoch 93/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0150 - val_loss: 0.0042\n",
      "Epoch 94/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0148 - val_loss: 0.0041\n",
      "Epoch 95/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0147 - val_loss: 0.0040\n",
      "Epoch 96/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0146 - val_loss: 0.0040\n",
      "Epoch 97/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0146 - val_loss: 0.0040\n",
      "Epoch 98/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0144 - val_loss: 0.0040\n",
      "Epoch 99/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0146 - val_loss: 0.0039\n",
      "Epoch 100/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0143 - val_loss: 0.0038\n",
      "Epoch 101/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0141 - val_loss: 0.0038\n",
      "Epoch 102/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0141 - val_loss: 0.0037\n",
      "Epoch 103/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0141 - val_loss: 0.0037\n",
      "Epoch 104/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0139 - val_loss: 0.0038\n",
      "Epoch 105/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0142 - val_loss: 0.0037\n",
      "Epoch 106/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0139 - val_loss: 0.0037\n",
      "Epoch 107/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0139 - val_loss: 0.0036\n",
      "Epoch 108/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0138 - val_loss: 0.0036\n",
      "Epoch 109/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0137 - val_loss: 0.0035\n",
      "Epoch 110/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0134 - val_loss: 0.0037\n",
      "Epoch 111/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0136 - val_loss: 0.0035\n",
      "Epoch 112/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0139 - val_loss: 0.0035\n",
      "Epoch 113/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0135 - val_loss: 0.0036\n",
      "Epoch 114/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0135 - val_loss: 0.0034\n",
      "Epoch 115/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0133 - val_loss: 0.0035\n",
      "Epoch 116/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0134 - val_loss: 0.0034\n",
      "Epoch 117/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0130 - val_loss: 0.0034\n",
      "Epoch 118/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0130 - val_loss: 0.0033\n",
      "Epoch 119/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0131 - val_loss: 0.0033\n",
      "Epoch 120/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0133 - val_loss: 0.0033\n",
      "Epoch 121/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0130 - val_loss: 0.0032\n",
      "Epoch 122/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0132 - val_loss: 0.0033\n",
      "Epoch 123/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0129 - val_loss: 0.0033\n",
      "Epoch 124/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0128 - val_loss: 0.0032\n",
      "Epoch 125/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0130 - val_loss: 0.0032\n",
      "Epoch 126/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0130 - val_loss: 0.0032\n",
      "Epoch 127/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0127 - val_loss: 0.0031\n",
      "Epoch 128/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0127 - val_loss: 0.0031\n",
      "Epoch 129/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0128 - val_loss: 0.0031\n",
      "Epoch 130/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0125 - val_loss: 0.0031\n",
      "Epoch 131/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0126 - val_loss: 0.0031\n",
      "Epoch 132/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0127 - val_loss: 0.0031\n",
      "Epoch 133/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0126 - val_loss: 0.0030\n",
      "Epoch 134/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0126 - val_loss: 0.0030\n",
      "Epoch 135/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0125 - val_loss: 0.0030\n",
      "Epoch 136/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0126 - val_loss: 0.0030\n",
      "Epoch 137/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0124 - val_loss: 0.0031\n",
      "Epoch 138/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0123 - val_loss: 0.0030\n",
      "Epoch 139/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0122 - val_loss: 0.0029\n",
      "Epoch 140/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0122 - val_loss: 0.0029\n",
      "Epoch 141/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0123 - val_loss: 0.0029\n",
      "Epoch 142/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0125 - val_loss: 0.0030\n",
      "Epoch 143/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0122 - val_loss: 0.0029\n",
      "Epoch 144/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0124 - val_loss: 0.0028\n",
      "Epoch 145/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0120 - val_loss: 0.0029\n",
      "Epoch 146/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0119 - val_loss: 0.0029\n",
      "Epoch 147/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0122 - val_loss: 0.0028\n",
      "Epoch 148/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0121 - val_loss: 0.0028\n",
      "Epoch 149/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0121 - val_loss: 0.0028\n",
      "Epoch 150/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0119 - val_loss: 0.0028\n",
      "Epoch 151/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0119 - val_loss: 0.0028\n",
      "Epoch 152/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0119 - val_loss: 0.0028\n",
      "Epoch 153/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0119 - val_loss: 0.0028\n",
      "Epoch 154/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0119 - val_loss: 0.0027\n",
      "Epoch 155/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0117 - val_loss: 0.0027\n",
      "Epoch 156/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0118 - val_loss: 0.0028\n",
      "Epoch 157/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0119 - val_loss: 0.0027\n",
      "Epoch 158/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0116 - val_loss: 0.0027\n",
      "Epoch 159/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0117 - val_loss: 0.0027\n",
      "Epoch 160/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0117 - val_loss: 0.0027\n",
      "Epoch 161/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0116 - val_loss: 0.0026\n",
      "Epoch 162/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0116 - val_loss: 0.0027\n",
      "Epoch 163/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0116 - val_loss: 0.0026\n",
      "Epoch 164/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0115 - val_loss: 0.0026\n",
      "Epoch 165/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0116 - val_loss: 0.0027\n",
      "Epoch 166/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0113 - val_loss: 0.0026\n",
      "Epoch 167/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0114 - val_loss: 0.0026\n",
      "Epoch 168/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0116 - val_loss: 0.0026\n",
      "Epoch 169/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0116 - val_loss: 0.0026\n",
      "Epoch 170/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0114 - val_loss: 0.0026\n",
      "Epoch 171/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0112 - val_loss: 0.0026\n",
      "Epoch 172/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0113 - val_loss: 0.0026\n",
      "Epoch 173/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0114 - val_loss: 0.0026\n",
      "Epoch 174/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0112 - val_loss: 0.0025\n",
      "Epoch 175/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0112 - val_loss: 0.0025\n",
      "Epoch 176/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0112 - val_loss: 0.0025\n",
      "Epoch 177/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0111 - val_loss: 0.0025\n",
      "Epoch 178/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0111 - val_loss: 0.0025\n",
      "Epoch 179/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0113 - val_loss: 0.0025\n",
      "Epoch 180/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0112 - val_loss: 0.0025\n",
      "Epoch 181/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0111 - val_loss: 0.0025\n",
      "Epoch 182/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0110 - val_loss: 0.0025\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "]\n",
    "result = model.fit(\n",
    "    [train_x_user, train_x_item], train_y_encoded,\n",
    "    batch_size = 512,\n",
    "    epochs = 1000,\n",
    "    shuffle = True,\n",
    "    verbose = True,\n",
    "    validation_data = ([test_x_user, test_x_item], test_y_encoded),\n",
    "    callbacks = callbacks,\n",
    ")\n",
    "\n",
    "model.save_weights('weights_DNN_onehot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1.014088260458625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y_encoded = model.predict([test_x_user, test_x_item]).reshape(-1,1)\n",
    "pred_y = pred_y_encoded.reshape(-1,5,).argmax(axis=1)\n",
    "\n",
    "print('RMSE : ', model.score(test_y, pred_y))\n",
    "scatter(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3_b) one-hot encoding with smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNModel_onehot(num_of_users, num_of_items, num_of_factors)\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 80000 samples\n",
      "Epoch 1/1000\n",
      "80000/80000 [==============================] - 2s 25us/sample - loss: 0.0612 - val_loss: 0.0516\n",
      "Epoch 2/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0533 - val_loss: 0.0495\n",
      "Epoch 3/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0516 - val_loss: 0.0481\n",
      "Epoch 4/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0503 - val_loss: 0.0468\n",
      "Epoch 5/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0490 - val_loss: 0.0447\n",
      "Epoch 6/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0473 - val_loss: 0.0420\n",
      "Epoch 7/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0451 - val_loss: 0.0391\n",
      "Epoch 8/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0426 - val_loss: 0.0357\n",
      "Epoch 9/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0400 - val_loss: 0.0325\n",
      "Epoch 10/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0371 - val_loss: 0.0290\n",
      "Epoch 11/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0345 - val_loss: 0.0263\n",
      "Epoch 12/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0320 - val_loss: 0.0235\n",
      "Epoch 13/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0298 - val_loss: 0.0209\n",
      "Epoch 14/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0277 - val_loss: 0.0189\n",
      "Epoch 15/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0259 - val_loss: 0.0172\n",
      "Epoch 16/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0243 - val_loss: 0.0155\n",
      "Epoch 17/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0229 - val_loss: 0.0142\n",
      "Epoch 18/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0216 - val_loss: 0.0131\n",
      "Epoch 19/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0205 - val_loss: 0.0120\n",
      "Epoch 20/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0196 - val_loss: 0.0111\n",
      "Epoch 21/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 22/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0177 - val_loss: 0.0096\n",
      "Epoch 23/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0170 - val_loss: 0.0090\n",
      "Epoch 24/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0162 - val_loss: 0.0083\n",
      "Epoch 25/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0156 - val_loss: 0.0077\n",
      "Epoch 26/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0149 - val_loss: 0.0073\n",
      "Epoch 27/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0143 - val_loss: 0.0067\n",
      "Epoch 28/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0138 - val_loss: 0.0062\n",
      "Epoch 29/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 30/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0126 - val_loss: 0.0055\n",
      "Epoch 31/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0122 - val_loss: 0.0052\n",
      "Epoch 32/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 33/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0113 - val_loss: 0.0045\n",
      "Epoch 34/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0109 - val_loss: 0.0042\n",
      "Epoch 35/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0107 - val_loss: 0.0040\n",
      "Epoch 36/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0104 - val_loss: 0.0038\n",
      "Epoch 37/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0102 - val_loss: 0.0036\n",
      "Epoch 38/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0100 - val_loss: 0.0035\n",
      "Epoch 39/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0097 - val_loss: 0.0033\n",
      "Epoch 40/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0094 - val_loss: 0.0031\n",
      "Epoch 41/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0092 - val_loss: 0.0031\n",
      "Epoch 42/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0090 - val_loss: 0.0028\n",
      "Epoch 43/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0089 - val_loss: 0.0028\n",
      "Epoch 44/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 45/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 46/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0085 - val_loss: 0.0025\n",
      "Epoch 47/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0082 - val_loss: 0.0024\n",
      "Epoch 48/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0082 - val_loss: 0.0023\n",
      "Epoch 49/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0080 - val_loss: 0.0022\n",
      "Epoch 50/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0080 - val_loss: 0.0022\n",
      "Epoch 51/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0079 - val_loss: 0.0021\n",
      "Epoch 52/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0078 - val_loss: 0.0020\n",
      "Epoch 53/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0077 - val_loss: 0.0020\n",
      "Epoch 54/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0075 - val_loss: 0.0019\n",
      "Epoch 55/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0075 - val_loss: 0.0019\n",
      "Epoch 56/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0073 - val_loss: 0.0018\n",
      "Epoch 57/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0074 - val_loss: 0.0018\n",
      "Epoch 58/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0072 - val_loss: 0.0017\n",
      "Epoch 59/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0071 - val_loss: 0.0017\n",
      "Epoch 60/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 61/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0070 - val_loss: 0.0016\n",
      "Epoch 62/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0069 - val_loss: 0.0016\n",
      "Epoch 63/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0068 - val_loss: 0.0015\n",
      "Epoch 64/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0068 - val_loss: 0.0015\n",
      "Epoch 65/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0068 - val_loss: 0.0015\n",
      "Epoch 66/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 67/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0066 - val_loss: 0.0014\n",
      "Epoch 68/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0065 - val_loss: 0.0014\n",
      "Epoch 69/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0065 - val_loss: 0.0014\n",
      "Epoch 70/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0065 - val_loss: 0.0014\n",
      "Epoch 71/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0063 - val_loss: 0.0013\n",
      "Epoch 72/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0064 - val_loss: 0.0013\n",
      "Epoch 73/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0064 - val_loss: 0.0013\n",
      "Epoch 74/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0063 - val_loss: 0.0013\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0062 - val_loss: 0.0013\n",
      "Epoch 76/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0062 - val_loss: 0.0012\n",
      "Epoch 77/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0061 - val_loss: 0.0012\n",
      "Epoch 78/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0060 - val_loss: 0.0012\n",
      "Epoch 79/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0060 - val_loss: 0.0011\n",
      "Epoch 80/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0060 - val_loss: 0.0011\n",
      "Epoch 81/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0060 - val_loss: 0.0011\n",
      "Epoch 82/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0060 - val_loss: 0.0011\n",
      "Epoch 83/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0059 - val_loss: 0.0011\n",
      "Epoch 84/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0058 - val_loss: 0.0011\n",
      "Epoch 85/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0059 - val_loss: 0.0011\n",
      "Epoch 86/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0058 - val_loss: 0.0010\n",
      "Epoch 87/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0057 - val_loss: 0.0010\n",
      "Epoch 88/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0056 - val_loss: 0.0010\n",
      "Epoch 89/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0058 - val_loss: 0.0010\n",
      "Epoch 90/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0057 - val_loss: 0.0011\n",
      "Epoch 91/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0056 - val_loss: 9.6651e-04\n",
      "Epoch 92/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0056 - val_loss: 0.0010\n",
      "Epoch 93/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0056 - val_loss: 9.9226e-04\n",
      "Epoch 94/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0055 - val_loss: 9.9462e-04\n",
      "Epoch 95/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0055 - val_loss: 9.3679e-04\n",
      "Epoch 96/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0055 - val_loss: 9.4936e-04\n",
      "Epoch 97/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0055 - val_loss: 9.2420e-04\n",
      "Epoch 98/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0055 - val_loss: 9.0590e-04\n",
      "Epoch 99/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0054 - val_loss: 9.2920e-04\n",
      "Epoch 100/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0054 - val_loss: 8.8331e-04\n",
      "Epoch 101/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0052 - val_loss: 8.7812e-04\n",
      "Epoch 102/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0052 - val_loss: 8.7365e-04\n",
      "Epoch 103/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0053 - val_loss: 8.5585e-04\n",
      "Epoch 104/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0053 - val_loss: 8.8743e-04\n",
      "Epoch 105/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0053 - val_loss: 8.6254e-04\n",
      "Epoch 106/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0053 - val_loss: 8.2380e-04\n",
      "Epoch 107/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0053 - val_loss: 8.3852e-04\n",
      "Epoch 108/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0051 - val_loss: 8.3215e-04\n",
      "Epoch 109/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0051 - val_loss: 8.1933e-04\n",
      "Epoch 110/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0052 - val_loss: 7.9815e-04\n",
      "Epoch 111/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0051 - val_loss: 7.9160e-04\n",
      "Epoch 112/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0051 - val_loss: 7.7852e-04\n",
      "Epoch 113/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0051 - val_loss: 8.0161e-04\n",
      "Epoch 114/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0051 - val_loss: 7.8302e-04\n",
      "Epoch 115/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0050 - val_loss: 7.5837e-04\n",
      "Epoch 116/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0050 - val_loss: 7.5690e-04\n",
      "Epoch 117/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0051 - val_loss: 7.4308e-04\n",
      "Epoch 118/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0051 - val_loss: 7.3376e-04\n",
      "Epoch 119/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0050 - val_loss: 7.3799e-04\n",
      "Epoch 120/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0049 - val_loss: 7.2306e-04\n",
      "Epoch 121/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0049 - val_loss: 7.4711e-04\n",
      "Epoch 122/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0049 - val_loss: 7.3893e-04\n",
      "Epoch 123/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0049 - val_loss: 7.3736e-04\n",
      "Epoch 124/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0050 - val_loss: 7.0693e-04\n",
      "Epoch 125/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0049 - val_loss: 6.9495e-04\n",
      "Epoch 126/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0048 - val_loss: 7.0142e-04\n",
      "Epoch 127/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.0048 - val_loss: 6.8517e-04\n",
      "Epoch 128/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0048 - val_loss: 7.2979e-04\n",
      "Epoch 129/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0048 - val_loss: 6.7059e-04\n",
      "Epoch 130/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0047 - val_loss: 6.8026e-04\n",
      "Epoch 131/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0048 - val_loss: 6.9700e-04\n",
      "Epoch 132/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0048 - val_loss: 6.8278e-04\n",
      "Epoch 133/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0048 - val_loss: 6.6097e-04\n",
      "Epoch 134/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0047 - val_loss: 6.7242e-04\n",
      "Epoch 135/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0048 - val_loss: 6.5930e-04\n",
      "Epoch 136/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0047 - val_loss: 6.6363e-04\n",
      "Epoch 137/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0047 - val_loss: 6.4593e-04\n",
      "Epoch 138/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0047 - val_loss: 6.5808e-04\n",
      "Epoch 139/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0047 - val_loss: 6.5155e-04\n",
      "Epoch 140/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0046 - val_loss: 6.3015e-04\n",
      "Epoch 141/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0046 - val_loss: 6.3113e-04\n",
      "Epoch 142/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0046 - val_loss: 6.4456e-04\n",
      "Epoch 143/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0046 - val_loss: 6.1526e-04\n",
      "Epoch 144/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0046 - val_loss: 6.1001e-04\n",
      "Epoch 145/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0046 - val_loss: 6.1453e-04\n",
      "Epoch 146/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0045 - val_loss: 6.4118e-04\n",
      "Epoch 147/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0045 - val_loss: 6.0384e-04\n",
      "Epoch 148/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0046 - val_loss: 6.0056e-04\n",
      "Epoch 149/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0045 - val_loss: 5.7242e-04\n",
      "Epoch 150/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0045 - val_loss: 6.2002e-04\n",
      "Epoch 151/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0045 - val_loss: 5.9667e-04\n",
      "Epoch 152/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0044 - val_loss: 5.8456e-04\n",
      "Epoch 153/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0045 - val_loss: 5.7808e-04\n",
      "Epoch 154/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.0045 - val_loss: 5.8730e-04\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "]\n",
    "result = model.fit(\n",
    "    [train_x_user, train_x_item], train_y_encoded_smoothing,\n",
    "    batch_size = 512,\n",
    "    epochs = 1000,\n",
    "    shuffle = True,\n",
    "    verbose = True,\n",
    "    validation_data = ([test_x_user, test_x_item], test_y_encoded_smoothing),\n",
    "    callbacks = callbacks,\n",
    ")\n",
    "\n",
    "model.save_weights('weights_DNN_onehot_smoothing.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1.0012804302491884\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y_encoded = model.predict([test_x_user, test_x_item]).reshape(-1,1)\n",
    "pred_y = pred_y_encoded.reshape(-1,5,).argmax(axis=1)\n",
    "\n",
    "print('RMSE : ', model.score(test_y, pred_y))\n",
    "scatter(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3_c) one-hot encoding - ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNModel_onehot(num_of_users, num_of_items, num_of_factors)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 80000 samples\n",
      "Epoch 1/1000\n",
      "80000/80000 [==============================] - 2s 26us/sample - loss: 0.5049 - val_loss: 0.4363\n",
      "Epoch 2/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4380 - val_loss: 0.4181\n",
      "Epoch 3/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4269 - val_loss: 0.4069\n",
      "Epoch 4/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4183 - val_loss: 0.3984\n",
      "Epoch 5/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4135 - val_loss: 0.4000\n",
      "Epoch 6/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4108 - val_loss: 0.3967\n",
      "Epoch 7/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4054 - val_loss: 0.3867\n",
      "Epoch 8/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.4022 - val_loss: 0.4035\n",
      "Epoch 9/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4050 - val_loss: 0.3792\n",
      "Epoch 10/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4118 - val_loss: 0.3935\n",
      "Epoch 11/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4028 - val_loss: 0.3842\n",
      "Epoch 12/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3951 - val_loss: 0.3718\n",
      "Epoch 13/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3906 - val_loss: 0.3685\n",
      "Epoch 14/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3916 - val_loss: 0.3670\n",
      "Epoch 15/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3857 - val_loss: 0.3642\n",
      "Epoch 16/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3868 - val_loss: 0.3665\n",
      "Epoch 17/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3842 - val_loss: 0.3571\n",
      "Epoch 18/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3769 - val_loss: 0.3505\n",
      "Epoch 19/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3718 - val_loss: 0.3557\n",
      "Epoch 20/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3776 - val_loss: 0.3568\n",
      "Epoch 21/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.3695 - val_loss: 0.3353\n",
      "Epoch 22/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3617 - val_loss: 0.3432\n",
      "Epoch 23/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3613 - val_loss: 0.3236\n",
      "Epoch 24/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3504 - val_loss: 0.3162\n",
      "Epoch 25/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3438 - val_loss: 0.3115\n",
      "Epoch 26/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3366 - val_loss: 0.2993\n",
      "Epoch 27/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3295 - val_loss: 0.2909\n",
      "Epoch 28/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3222 - val_loss: 0.2975\n",
      "Epoch 29/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3211 - val_loss: 0.2767\n",
      "Epoch 30/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3148 - val_loss: 0.2680\n",
      "Epoch 31/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3046 - val_loss: 0.2622\n",
      "Epoch 32/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2986 - val_loss: 0.2684\n",
      "Epoch 33/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3012 - val_loss: 0.2491\n",
      "Epoch 34/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.2891 - val_loss: 0.2473\n",
      "Epoch 35/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2869 - val_loss: 0.2635\n",
      "Epoch 36/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2975 - val_loss: 0.2479\n",
      "Epoch 37/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2790 - val_loss: 0.2338\n",
      "Epoch 38/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2714 - val_loss: 0.2185\n",
      "Epoch 39/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2710 - val_loss: 0.2212\n",
      "Epoch 40/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2597 - val_loss: 0.2058\n",
      "Epoch 41/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2639 - val_loss: 0.2092\n",
      "Epoch 42/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.2599 - val_loss: 0.2144\n",
      "Epoch 43/1000\n",
      "80000/80000 [==============================] - 1s 17us/sample - loss: 0.2684 - val_loss: 0.2274\n",
      "Epoch 44/1000\n",
      "80000/80000 [==============================] - 1s 17us/sample - loss: 0.2636 - val_loss: 0.2021\n",
      "Epoch 45/1000\n",
      "80000/80000 [==============================] - 1s 17us/sample - loss: 0.2525 - val_loss: 0.1934\n",
      "Epoch 46/1000\n",
      "80000/80000 [==============================] - 1s 17us/sample - loss: 0.2423 - val_loss: 0.1893\n",
      "Epoch 47/1000\n",
      "80000/80000 [==============================] - 1s 17us/sample - loss: 0.2391 - val_loss: 0.1865\n",
      "Epoch 48/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.2327 - val_loss: 0.1822\n",
      "Epoch 49/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2262 - val_loss: 0.1710\n",
      "Epoch 50/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2219 - val_loss: 0.1643\n",
      "Epoch 51/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2190 - val_loss: 0.1696\n",
      "Epoch 52/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2217 - val_loss: 0.1637\n",
      "Epoch 53/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2218 - val_loss: 0.1899\n",
      "Epoch 54/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2277 - val_loss: 0.1750\n",
      "Epoch 55/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2260 - val_loss: 0.1717\n",
      "Epoch 56/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2178 - val_loss: 0.1597\n",
      "Epoch 57/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2110 - val_loss: 0.1527\n",
      "Epoch 58/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.2039 - val_loss: 0.1468\n",
      "Epoch 59/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.2018 - val_loss: 0.1568\n",
      "Epoch 60/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.2014 - val_loss: 0.1462\n",
      "Epoch 61/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1998 - val_loss: 0.1429\n",
      "Epoch 62/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1935 - val_loss: 0.1445\n",
      "Epoch 63/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1967 - val_loss: 0.1394\n",
      "Epoch 64/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1964 - val_loss: 0.1416\n",
      "Epoch 65/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1924 - val_loss: 0.1389\n",
      "Epoch 66/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1969 - val_loss: 0.1314\n",
      "Epoch 67/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1975 - val_loss: 0.1427\n",
      "Epoch 68/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1937 - val_loss: 0.1308\n",
      "Epoch 69/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1860 - val_loss: 0.1253\n",
      "Epoch 70/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1907 - val_loss: 0.1282\n",
      "Epoch 71/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1934 - val_loss: 0.1425\n",
      "Epoch 72/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1898 - val_loss: 0.1312\n",
      "Epoch 73/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.1880 - val_loss: 0.1247\n",
      "Epoch 74/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1819 - val_loss: 0.1255\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1949 - val_loss: 0.1511\n",
      "Epoch 76/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1896 - val_loss: 0.1292\n",
      "Epoch 77/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1797 - val_loss: 0.1172\n",
      "Epoch 78/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1756 - val_loss: 0.1184\n",
      "Epoch 79/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1720 - val_loss: 0.1139\n",
      "Epoch 80/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1720 - val_loss: 0.1255\n",
      "Epoch 81/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1819 - val_loss: 0.1310\n",
      "Epoch 82/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1862 - val_loss: 0.1254\n",
      "Epoch 83/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1769 - val_loss: 0.1163\n",
      "Epoch 84/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.1687 - val_loss: 0.1149\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "]\n",
    "result = model.fit(\n",
    "    [train_x_user, train_x_item], train_y_encoded,\n",
    "    batch_size = 512,\n",
    "    epochs = 1000,\n",
    "    shuffle = True,\n",
    "    verbose = True,\n",
    "    validation_data = ([test_x_user, test_x_item], test_y_encoded),\n",
    "    callbacks = callbacks,\n",
    ")\n",
    "\n",
    "model.save_weights('weights_DNN_onehot_ce.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1.075534750717056\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y_encoded = model.predict([test_x_user, test_x_item]).reshape(-1,1)\n",
    "pred_y = pred_y_encoded.reshape(-1,5,).argmax(axis=1)\n",
    "\n",
    "print('RMSE : ', model.score(test_y, pred_y))\n",
    "scatter(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3_d) one-hot encoding with smoothing - ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNModel_onehot(num_of_users, num_of_items, num_of_factors)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 80000 samples\n",
      "Epoch 1/1000\n",
      "80000/80000 [==============================] - 2s 28us/sample - loss: 0.4990 - val_loss: 0.4511\n",
      "Epoch 2/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4543 - val_loss: 0.4373\n",
      "Epoch 3/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4481 - val_loss: 0.4366\n",
      "Epoch 4/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4442 - val_loss: 0.4316\n",
      "Epoch 5/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4400 - val_loss: 0.4258\n",
      "Epoch 6/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4358 - val_loss: 0.4237\n",
      "Epoch 7/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4335 - val_loss: 0.4210\n",
      "Epoch 8/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4308 - val_loss: 0.4193\n",
      "Epoch 9/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4298 - val_loss: 0.4195\n",
      "Epoch 10/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.4334 - val_loss: 0.4283\n",
      "Epoch 11/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.4290 - val_loss: 0.4155\n",
      "Epoch 12/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4297 - val_loss: 0.4172\n",
      "Epoch 13/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4243 - val_loss: 0.4125\n",
      "Epoch 14/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4201 - val_loss: 0.4071\n",
      "Epoch 15/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4183 - val_loss: 0.4028\n",
      "Epoch 16/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4142 - val_loss: 0.3989\n",
      "Epoch 17/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4093 - val_loss: 0.3957\n",
      "Epoch 18/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.4069 - val_loss: 0.3881\n",
      "Epoch 19/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.4013 - val_loss: 0.3827\n",
      "Epoch 20/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3974 - val_loss: 0.3829\n",
      "Epoch 21/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3937 - val_loss: 0.3732\n",
      "Epoch 22/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3908 - val_loss: 0.3842\n",
      "Epoch 23/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.3892 - val_loss: 0.3664\n",
      "Epoch 24/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3840 - val_loss: 0.3635\n",
      "Epoch 25/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3892 - val_loss: 0.3719\n",
      "Epoch 26/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3841 - val_loss: 0.3595\n",
      "Epoch 27/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3762 - val_loss: 0.3545\n",
      "Epoch 28/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3761 - val_loss: 0.3614\n",
      "Epoch 29/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3761 - val_loss: 0.3508\n",
      "Epoch 30/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3695 - val_loss: 0.3480\n",
      "Epoch 31/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.3682 - val_loss: 0.3447\n",
      "Epoch 32/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3688 - val_loss: 0.3467\n",
      "Epoch 33/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3696 - val_loss: 0.3579\n",
      "Epoch 34/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3693 - val_loss: 0.3444\n",
      "Epoch 35/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3734 - val_loss: 0.3607\n",
      "Epoch 36/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.3683 - val_loss: 0.3455\n",
      "Epoch 37/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3620 - val_loss: 0.3395\n",
      "Epoch 38/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.3593 - val_loss: 0.3396\n",
      "Epoch 39/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3586 - val_loss: 0.3374\n",
      "Epoch 40/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3568 - val_loss: 0.3406\n",
      "Epoch 41/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3549 - val_loss: 0.3325\n",
      "Epoch 42/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3525 - val_loss: 0.3307\n",
      "Epoch 43/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3518 - val_loss: 0.3310\n",
      "Epoch 44/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3524 - val_loss: 0.3299\n",
      "Epoch 45/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3503 - val_loss: 0.3270\n",
      "Epoch 46/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3583 - val_loss: 0.3394\n",
      "Epoch 47/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3533 - val_loss: 0.3290\n",
      "Epoch 48/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3490 - val_loss: 0.3315\n",
      "Epoch 49/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.3476 - val_loss: 0.3252\n",
      "Epoch 50/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3463 - val_loss: 0.3328\n",
      "Epoch 51/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3477 - val_loss: 0.3260\n",
      "Epoch 52/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3465 - val_loss: 0.3270\n",
      "Epoch 53/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3476 - val_loss: 0.3237\n",
      "Epoch 54/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3441 - val_loss: 0.3214\n",
      "Epoch 55/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3415 - val_loss: 0.3200\n",
      "Epoch 56/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3408 - val_loss: 0.3206\n",
      "Epoch 57/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3419 - val_loss: 0.3193\n",
      "Epoch 58/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3393 - val_loss: 0.3167\n",
      "Epoch 59/1000\n",
      "80000/80000 [==============================] - 1s 18us/sample - loss: 0.3369 - val_loss: 0.3177\n",
      "Epoch 60/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3370 - val_loss: 0.3146\n",
      "Epoch 61/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.3352 - val_loss: 0.3125\n",
      "Epoch 62/1000\n",
      "80000/80000 [==============================] - 1s 16us/sample - loss: 0.3356 - val_loss: 0.3141\n",
      "Epoch 63/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3365 - val_loss: 0.3241\n",
      "Epoch 64/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3361 - val_loss: 0.3123\n",
      "Epoch 65/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3340 - val_loss: 0.3143\n",
      "Epoch 66/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3334 - val_loss: 0.3106\n",
      "Epoch 67/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3304 - val_loss: 0.3096\n",
      "Epoch 68/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3348 - val_loss: 0.3173\n",
      "Epoch 69/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3344 - val_loss: 0.3165\n",
      "Epoch 70/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3355 - val_loss: 0.3140\n",
      "Epoch 71/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3348 - val_loss: 0.3314\n",
      "Epoch 72/1000\n",
      "80000/80000 [==============================] - 1s 15us/sample - loss: 0.3410 - val_loss: 0.3153\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "]\n",
    "result = model.fit(\n",
    "    [train_x_user, train_x_item], train_y_encoded_smoothing,\n",
    "    batch_size = 512,\n",
    "    epochs = 1000,\n",
    "    shuffle = True,\n",
    "    verbose = True,\n",
    "    validation_data = ([test_x_user, test_x_item], test_y_encoded_smoothing),\n",
    "    callbacks = callbacks,\n",
    ")\n",
    "\n",
    "model.save_weights('weights_DNN_onehot_smoothing_ce.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1.0387853483756881\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y_encoded = model.predict([test_x_user, test_x_item]).reshape(-1,1)\n",
    "pred_y = pred_y_encoded.reshape(-1,5,).argmax(axis=1)\n",
    "\n",
    "print('RMSE : ', model.score(test_y, pred_y))\n",
    "scatter(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
